{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpnTxnA1oWovcDgl8W7m7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksasekulicfon/Napredna-analiza-podataka/blob/main/Final_NAP_Projekat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Uvod i pozicioniranje eksperimenta\n",
        "\n",
        "Prikazani segment koda predstavlja početnu pripremu eksperimenta čiji je cilj poređenje tri pristupa klasifikaciji teksta: (1) klasičnog machine learning pristupa, (2) zero-shot klasifikacije zasnovane na promptovanju LLM-a i (3) few-shot klasifikacije kao proširenja zero-shot pristupa uvođenjem malog broja primera u prompt.\n",
        "\n",
        " Predmet analize je sentiment u tvitovima na nivou entiteta, gde se sentiment određuje u odnosu na navedeni entitet, a ne samo na osnovu samog teksta poruke.\n",
        "\n",
        "Korišćeni skup podataka je javno dostupan “Twitter Entity Sentiment Analysis” dataset preuzet sa Kaggle, pri čemu zapis sadrži entitet, tekst tvita i oznaku sentimenta."
      ],
      "metadata": {
        "id": "9_0bui5GewNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instalacija biblioteka i formiranje radnog okruženja\n",
        "\n",
        "Prvi korak je instalacija paketa koji pokrivaju sve faze rada: obradu podataka (pandas, numpy), klasično učenje i evaluaciju (scikit-learn), rad sa velikim jezičkim modelima (transformers, torch, accelerate), vizuelizacije (matplotlib, seaborn), kao i orkestraciju LLM poziva i standardizaciju promptovanja (langchain i langchain_groq). Ovakav izbor alata odgovara metodologiji koja eksplicitno predviđa paralelnu upotrebu klasičnog ML pristupa i LLM pristupa (zero-shot/few-shot).\n",
        "\n",
        "Nakon instalacije sledi učitavanje (import) biblioteka. Time se obezbeđuje da su dostupni svi ključni objekti: TF-IDF vektorizator i klasifikatori za klasični ML pipeline, metrike za evaluaciju (accuracy, precision/recall/F1 i confusion matrix), kao i tokenizer i model iz Hugging Face ekosistema za LLM deo eksperimenta. Sama struktura import-a nagoveštava kasniji tok: najpre obrada i priprema teksta, zatim treniranje/validacija klasičnog modela, i na kraju LLM evaluacija kroz promptove."
      ],
      "metadata": {
        "id": "pxeoKK25e439"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detekcija hardverskog okruženja (CPU/GPU)\n",
        "\n",
        "Deo koda koji proverava dostupnost CUDA podrške (torch.cuda.is_available()) služi da se automatski identifikuje da li je moguće izvršavanje na GPU-u. Iako se u ovom isečku još ne prebacuju modeli na uređaj, ovakva provera je standardna priprema za kasniju fazu, gde se inference ili obrada sa modelima može značajno ubrzati korišćenjem GPU-a.\n",
        "\n",
        "#Učitavanje skupa podataka i definisanje strukture zapisa\n",
        "\n",
        "Kôd zatim definiše očekivanu strukturu zapisa kroz četiri kolone: ID zapisa/tvita, entitet, oznaku klase/sentimenta i tekst tvita.\n",
        "\n",
        " Nakon toga se učitavaju dve datoteke koje čine osnovu eksperimenta: twitter_training.csv kao trening skup i twitter_validation.csv kao validacioni skup.\n",
        "\n",
        " U dokumentu je naglašeno i da su u originalnom dataset-u prisutne oznake Positive, Negative, Neutral i Irrelevant, uz napomenu da se Irrelevant može tretirati kao Neutral kako bi se problem sveo na tri klase.\n",
        "\n",
        "U samom kodu se dodatno uklanjaju redovi bez tekstualnog sadržaja (dropna(subset=['text'])), čime se obezbeđuje da dalji koraci (vektorizacija, treniranje i promptovanje) rade nad validnim tekstualnim ulazima.\n",
        "\n",
        "#Konstrukcija tekstualnog ulaza koji čuva “entity-level” definiciju\n",
        "\n",
        "Ključni korak u pripremi podataka je formiranje nove kolone input_text, gde se entitet i tekst tvita konkateniraju u jedinstven string oblika:\n",
        "\n",
        "entity: <ENTITET> | tweet: <TEKST>\n",
        "\n",
        "Ovaj format eksplicitno uvodi entitet kao deo tekstualnog konteksta, čime se zadržava definicija zadatka (sentiment “o entitetu”), dok ulaz ostaje isključivo tekstualnog tipa.\n",
        "\n",
        " Takva formulacija je posebno korisna jer omogućava da i klasični ML modeli (koji očekuju tekst) i LLM pristupi (koji rade nad promptom) dobiju ujednačen, porediv ulaz, bez gubitka informacije o tome prema kome je sentiment usmeren.\n",
        "\n",
        "#Brza provera ispravnosti pripreme\n",
        "\n",
        "Na kraju se ispisuje jedan primer iz input_text kolone. Ovaj ispis ima ulogu “sanity check”-a: potvrđuje da su CSV fajlovi pravilno učitani, da su kolone korektno mapirane i da je format ulaza uspešno formiran pre ulaska u naredne faze eksperimenta (vektorizacija, treniranje i LLM evaluacija)."
      ],
      "metadata": {
        "id": "W5j9VMV-fBb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6rGn9Qo7q9n"
      },
      "outputs": [],
      "source": [
        "# 1. Instalacija i Učitavanje\n",
        "!pip install pandas scikit-learn transformers accelerate torch matplotlib seaborn langchain langchain_groq -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "from sklearn.pipeline import Pipeline\n",
        "import re\n",
        "import json\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Podešen uređaj: {device}\")\n",
        "\n",
        "columns = ['id', 'entity', 'sentiment', 'text']\n",
        "train_df = pd.read_csv('twitter_training.csv', names=columns, header=None).dropna(subset=['text'])\n",
        "val_df = pd.read_csv('twitter_validation.csv', names=columns, header=None).dropna(subset=['text'])\n",
        "\n",
        "train_df['input_text'] = \"entity: \" + train_df['entity'] + \" | tweet: \" + train_df['text']\n",
        "val_df['input_text'] = \"entity: \" + val_df['entity'] + \" | tweet: \" + val_df['text']\n",
        "\n",
        "print(\"Primer ulaznog podatka:\", train_df['input_text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Klasični Machine Learning (ML)"
      ],
      "metadata": {
        "id": "9gEvIz7h8Qai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Priprema teksta i implementacija klasičnog ML pristupa\n",
        "\n",
        "Nakon inicijalnog učitavanja skupa podataka, sledeći korak je priprema tekstualnog sadržaja za klasičnu obradu i treniranje modela. U tu svrhu uvodi se jednostavna funkcija za čišćenje teksta, čiji je cilj da ukloni elemente koji često predstavljaju šum u tvitovima (linkove, oznake korisnika i razne simbole), a da istovremeno sačuva deo izražajnih signala poput uzvičnika i upitnika.\n",
        "\n",
        "Funkcija smart_clean_text najpre osigurava da je ulaz uvek string, zatim uklanja URL-ove (npr. http...), briše “mention” oznake korisnika (npr. @username), a potom odstranjuje sve karaktere koji nisu slova, razmaci ili osnovni interpunkcijski znaci ! i ?. Na kraju se tekst prevodi u mala slova. Ova transformacija ima dve glavne posledice: (1) smanjuje se broj različitih tokena (npr. “Game” i “game” postaju isto), i (2) model dobija “čistiji” ulaz gde dominiraju reči i osnovna emotivna interpunkcija, što može poboljšati stabilnost TF-IDF reprezentacije.\n",
        "\n",
        "Dobijeni čisti tekst se čuva u novim kolonama clean_text i za trening i za validacioni skup, čime se obezbeđuje da oba skupa prolaze kroz identičnu pripremu. Nakon toga se ponovo formira kolona input_text u standardizovanom formatu “entity: … | tweet: …”, ali sada koristeći očišćenu verziju tvita. Time se dodatno osigurava da se entitet ne izgubi i da ulaz ostane usmeren na entity-level sentiment.\n",
        "\n",
        "#Konsolidacija klasa: tretiranje “Irrelevant” kao “Neutral”\n",
        "\n",
        "Pre treniranja modela, oznaka sentimenta “Irrelevant” se mapira na “Neutral”. Ovaj korak ima praktičnu svrhu: umesto da se model bavi dodatnom klasom koja često predstavlja “neodnos prema entitetu”, problem se svodi na tri standardne klase (Positive, Negative, Neutral). Na taj način evaluacija postaje preglednija, a klasifikator se fokusira na distinkciju koja je obično najznačajnija u sentiment analizi.\n",
        "\n",
        "#Pipeline: TF-IDF + Linearni SVM kao jaka bazna linija\n",
        "\n",
        "Centralni deo pristupa je izgradnja Pipeline objekta koji spaja dve faze u jedan konzistentan tok obrade:\n",
        "\n",
        "TF-IDF vektorizacija\n",
        "Tekst se pretvara u numeričku reprezentaciju pomoću TF-IDF pristupa. Podešavanja su izabrana tako da uhvate i pojedinačne reči i kratke fraze:\n",
        "\n",
        "ngram_range=(1,3) omogućava unigrame, bigrame i trigrame, što često pomaže u sentimentu jer se negativni/pozitivni ton neretko izražava kroz fraze (“not good”, “very bad”, “so happy”).\n",
        "\n",
        "max_features=25000 ograničava dimenzionalnost na najrelevantnije karakteristike kako bi model ostao efikasan.\n",
        "\n",
        "min_df=2 izbacuje termine koji se pojavljuju veoma retko, jer su često šum i slabo generalizuju.\n",
        "\n",
        "max_df=0.9 uklanja termine koji se pojavljuju u gotovo svim dokumentima (previše opšti termini), jer ne nose diskriminativnu informaciju.\n",
        "\n",
        "LinearSVC (linearni SVM klasifikator)\n",
        "Na TF-IDF vektorima trenira se linearni SVM. Linearni SVM je česta i vrlo jaka bazna metoda za klasifikaciju teksta, naročito kada se koristi TF-IDF sa n-gramima. Parametri poput max_iter=5000 obezbeđuju dovoljno iteracija za konvergenciju, dok random_state=42 obezbeđuje reproduktivnost.\n",
        "\n",
        "#Optimizacija hiperparametara: Grid Search sa unakrsnom validacijom\n",
        "\n",
        "Da bi se dobila najbolja moguća varijanta SVM modela, koristi se GridSearchCV. Umesto ručnog pogađanja parametara, pretražuje se mreža kombinacija:\n",
        "\n",
        "clf__C: jačina regularizacije (0.1, 1, 10). Manje vrednosti više “peglaju” model (više regularizacije), veće vrednosti dopuštaju složenije granice odluke.\n",
        "\n",
        "clf__class_weight: ili bez težina, ili balanced. Opcija balanced je korisna kada klase nisu jednako zastupljene, jer automatski pojačava važnost ređih klasa.\n",
        "\n",
        "tfidf__sublinear_tf: uključivanje sublinear TF skaliranja (True/False), što može pomoći jer ublažava efekat ekstremno čestih reči u pojedinačnom dokumentu.\n",
        "\n",
        "Unakrsna validacija cv=3 deli trening skup na tri dela i rotira treniranje/validaciju, čime se smanjuje rizik da izabrani parametri budu “srećno pogođeni” na jednoj podeli. n_jobs=-1 koristi sve dostupne CPU jezgre radi bržeg pretraživanja, a verbose=1 služi da se proces prati tokom izvršavanja.\n",
        "\n",
        "Kada se završi pretraga, ispisuju se najbolji parametri i uzima se najbolji model (best_estimator_) za finalnu evaluaciju na validacionom skupu.\n",
        "\n",
        "#Evaluacija: tačnost, detaljan izveštaj i matrica konfuzije\n",
        "\n",
        "Najbolji model se zatim koristi da predvidi sentiment za val_df['input_text']. Evaluacija se radi na nekoliko nivoa:\n",
        "\n",
        "Accuracy daje ukupni procenat tačno klasifikovanih primera.\n",
        "\n",
        "classification_report prikazuje preciznost, odziv i F1 meru po klasama, što je važno jer model može imati dobru ukupnu tačnost, a da pritom loše radi na jednoj klasi (npr. Neutral).\n",
        "\n",
        "confusion_matrix daje uvid u tipične greške: npr. da li model često meša Neutral sa Negative, ili Positive sa Neutral.\n",
        "\n",
        "Vizuelizacija matrice konfuzije kroz heatmap prikaz dodatno olakšava interpretaciju, jer se odmah vidi gde su najveća “curenja” između klasa. Oznake su svedene na kratke forme (Pos/Neg/Neu) radi čitljivosti, a naslov jasno navodi da se radi o SVM modelu."
      ],
      "metadata": {
        "id": "YPoZIp5DfeWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "def smart_clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "train_df['clean_text'] = train_df['text'].apply(smart_clean_text)\n",
        "val_df['clean_text'] = val_df['text'].apply(smart_clean_text)\n",
        "\n",
        "train_df['input_text'] = \"entity: \" + train_df['entity'] + \" | tweet: \" + train_df['clean_text']\n",
        "val_df['input_text'] = \"entity: \" + val_df['entity'] + \" | tweet: \" + val_df['clean_text']\n",
        "\n",
        "train_df['sentiment'] = train_df['sentiment'].replace('Irrelevant', 'Neutral')\n",
        "val_df['sentiment'] = val_df['sentiment'].replace('Irrelevant', 'Neutral')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=25000,\n",
        "        ngram_range=(1, 3),\n",
        "        min_df=2,\n",
        "        max_df=0.9\n",
        "    )),\n",
        "    ('clf', LinearSVC(\n",
        "        random_state=42,\n",
        "        dual='auto',\n",
        "        max_iter=5000\n",
        "    ))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'clf__C': [0.1, 1, 10],\n",
        "    'clf__class_weight': [None, 'balanced'],\n",
        "    'tfidf__sublinear_tf': [True, False]\n",
        "}\n",
        "\n",
        "print(\"\\nPokrećem optimizaciju SVM modela (Grid Search)...\")\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_df['input_text'], train_df['sentiment'])\n",
        "\n",
        "print(f\"Najbolji parametri: {grid_search.best_params_}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(val_df['input_text'])\n",
        "y_val = val_df['sentiment']\n",
        "\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n--- MAKSIMALNA TAČNOST SA SVM: {acc:.4f} ---\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_val, y_pred, labels=['Positive', 'Negative', 'Neutral'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Pos', 'Neg', 'Neu'],\n",
        "            yticklabels=['Pos', 'Neg', 'Neu'])\n",
        "plt.title('Confusion Matrix (SVM Model)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2rlnUWqYBpTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Učitavanje i pozivanje LLM-a preko Groq servisa\n",
        "\n",
        "Ovaj segment koda uvodi treći deo eksperimenta: rad sa velikim jezičkim modelom (LLM) bez treniranja, kroz pozive eksternom servisu. Ideja je da se umesto klasičnog “fit” procesa koristi inference (odgovaranje modela na prompt), čime se omogućava zero-shot ili few-shot klasifikacija sentimenta. Da bi taj pristup bio stabilan u praksi, kod obuhvata tri ključne celine: (1) bezbedno preuzimanje API ključa, (2) inicijalizaciju LLM klijenta sa kontrolisanim parametrima i (3) robusnu funkciju za slanje prompta sa keširanjem i retry mehanizmom.\n",
        "\n",
        "#1) Log poruka i importi za mrežni poziv\n",
        "\n",
        "Na početku se štampa poruka koja služi kao marker u notebook-u da započinje sekcija učitavanja LLM-a. Zatim se uvoze biblioteke:\n",
        "\n",
        "os za čitanje i postavljanje promenljivih okruženja (API ključ),\n",
        "\n",
        "random i sleep za uvođenje nasumične pauze između ponovnih pokušaja,\n",
        "\n",
        "ChatGroq iz langchain_groq kao klijent koji pojednostavljuje pozive Groq API-ju.\n",
        "\n",
        "Ovo je tipična priprema za mrežno pozivanje LLM-a gde se očekuju povremeni prekidi ili rate-limit situacije.\n",
        "\n",
        "#2) Bezbedno učitavanje GROQ_API_KEY ključa\n",
        "\n",
        "Funkcija get_groq_key() rešava čest problem: isti kod treba da radi i lokalno i u Google Colab okruženju.\n",
        "\n",
        "Mehanizam je postavljen hijerarhijski:\n",
        "\n",
        "Prvo se proverava sistemsko okruženje (os.getenv(\"GROQ_API_KEY\")).\n",
        "Ako postoji, odmah se vraća ključ.\n",
        "\n",
        "Ako ne postoji, pokušava se učitavanje iz Colab userdata (kroz google.colab.userdata).\n",
        "Ako se ključ pronađe, dodatno se setuje i u os.environ[\"GROQ_API_KEY\"], što je praktično jer sve kasnije biblioteke koje očekuju env var sada mogu da je vide.\n",
        "\n",
        "Ako oba izvora zakažu, baca se RuntimeError, čime se eksplicitno prekida izvršavanje i jasno signalizira da bez ključa nema daljeg rada.\n",
        "\n",
        "Poziv get_groq_key() odmah nakon definicije funkcije je nameran: cilj je da se greška detektuje što ranije, pre nego što se napravi klijent ili krene sa pozivima modela.\n",
        "\n",
        "#3) Izbor modela i inicijalizacija ChatGroq klijenta\n",
        "\n",
        "Zatim se definiše:\n",
        "\n",
        "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "\n",
        "što znači da će se koristiti konkretna varijanta Llama modela, optimizovana za brze odgovore.\n",
        "\n",
        "Nakon toga se pravi llm = ChatGroq(...) sa važnim parametrima:\n",
        "\n",
        "temperature=0.0: model postaje maksimalno determinističan.\n",
        "To je posebno bitno za klasifikaciju sentimenta, jer se očekuje konzistentan izlaz (npr. uvek “Positive/Negative/Neutral”), a ne kreativne varijacije.\n",
        "\n",
        "max_tokens=6: ograničava dužinu odgovora na veoma kratku formu.\n",
        "Za klasifikaciju je često dovoljno 1–2 reči (“Positive”, “Negative”, “Neutral”), pa se ovim smanjuje rizik da model generiše objašnjenja, dodatne rečenice ili “priču” umesto etikete.\n",
        "\n",
        "Ovaj deo praktično “zakucava” LLM da se ponaša kao klasifikator, a ne kao chat asistent.\n",
        "\n",
        "#4) Keširanje odgovora radi brzine i stabilnosti\n",
        "\n",
        "Definiše se _cache: dict[str, str] = {} kao rečnik koji mapira prompt → odgovor.\n",
        "\n",
        "Keš ima dve funkcije:\n",
        "\n",
        "Ubrzanje: ako se isti prompt ponovo pošalje (što se često dešava u evaluaciji ili pri grešci), rezultat se odmah vraća bez novog API poziva.\n",
        "\n",
        "Stabilnost i trošak: smanjuje broj zahteva prema servisu, što smanjuje šansu za rate limit i ubrzava workflow.\n",
        "\n",
        "#5) Funkcija query_llm: robustan poziv sa retry + exponential backoff\n",
        "\n",
        "Funkcija query_llm(...) je centralni deo celog segmenta. Ona pretvara poziv modelu u “siguran” API:\n",
        "\n",
        "##5.1 Validacija ulaza\n",
        "\n",
        "Najpre se prompt “trimuje” i proverava da nije prazan. Ako jeste, vraća se prazan string. Ovo sprečava besmislene pozive.\n",
        "\n",
        "##5.2 Keš pre mreže\n",
        "\n",
        "Ako je use_cache=True i prompt postoji u _cache, vraća se keširana vrednost. To je najbrži put.\n",
        "\n",
        "##5.3 Retry petlja\n",
        "\n",
        "Ako nije u kešu, funkcija pokušava da pozove:\n",
        "\n",
        "text = (llm.invoke(prompt).content or \"\").strip()\n",
        "\n",
        "\n",
        "i vrati sadržaj odgovora.\n",
        "\n",
        "Ako dođe do izuzetka (mrežni prekid, rate limit, timeout, backend error), hvata se greška i prelazi se na sledeći pokušaj sve do retries.\n",
        "\n",
        "##5.4 Exponential backoff + jitter\n",
        "\n",
        "Između pokušaja se pravi pauza:\n",
        "\n",
        "osnovni delay raste eksponencijalno (base_delay * 2^(attempt-1)),\n",
        "\n",
        "“seče” se na max_delay da pauze ne postanu preduge,\n",
        "\n",
        "dodaje se mali slučajni dodatak (random.uniform(0, 0.25)) da se izbegne situacija da više procesa “udari” u isti trenutak (tzv. jitter).\n",
        "\n",
        "Ovaj pattern je standard u mrežnim sistemima jer značajno povećava šanse da sledeći pokušaj uspe.\n",
        "\n",
        "##5.5 Kontrolisani fallback\n",
        "\n",
        "Ako ni posle svih pokušaja poziv ne uspe, štampa se upozorenje i vraća prazan string. Time se omogućava da ostatak evaluacije nastavi (npr. da se preskoči taj primer), umesto da ceo proces pukne."
      ],
      "metadata": {
        "id": "Mz3vhDqggXOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Učitavanje LLM Modela (Groq) ---\")\n",
        "\n",
        "import os\n",
        "import random\n",
        "from time import sleep\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "def get_groq_key() -> str:\n",
        "    key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if key:\n",
        "        return key\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        key = userdata.get(\"GROQ_API_KEY\")\n",
        "        if key:\n",
        "            os.environ[\"GROQ_API_KEY\"] = key\n",
        "            return key\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    raise RuntimeError(\"GROQ_API_KEY nije pronađen (ni ENV ni Colab userdata).\")\n",
        "\n",
        "\n",
        "get_groq_key()\n",
        "\n",
        "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=GROQ_MODEL,\n",
        "    temperature=0.0,\n",
        "    max_tokens=6,\n",
        ")\n",
        "\n",
        "_cache: dict[str, str] = {}\n",
        "\n",
        "\n",
        "def query_llm(\n",
        "    prompt: str,\n",
        "    retries: int = 5,\n",
        "    base_delay: float = 0.7,\n",
        "    max_delay: float = 8.0,\n",
        "    use_cache: bool = True,\n",
        ") -> str:\n",
        "    prompt = (prompt or \"\").strip()\n",
        "    if not prompt:\n",
        "        return \"\"\n",
        "\n",
        "    if use_cache and prompt in _cache:\n",
        "        return _cache[prompt]\n",
        "\n",
        "    last_err = None\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            text = (llm.invoke(prompt).content or \"\").strip()\n",
        "            if use_cache:\n",
        "                _cache[prompt] = text\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if attempt == retries:\n",
        "                break\n",
        "            delay = min(max_delay, base_delay * (2 ** (attempt - 1))) + random.uniform(0, 0.25)\n",
        "            sleep(delay)\n",
        "\n",
        "    print(f\"[WARN] Groq poziv nije uspeo nakon {retries} pokušaja: {last_err}\")\n",
        "    return \"\"\n",
        "\n",
        "print(f\"Model učitan! Groq model: {GROQ_MODEL}\")"
      ],
      "metadata": {
        "id": "Qp8Kx-PH8pgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zero-shot klasifikacija sentimenta na nivou entiteta (3 klase)\n",
        "\n",
        "Ovaj segment koda predstavlja implementaciju zero-shot pristupa za klasifikaciju sentimenta, gde se veliki jezički model koristi kao “gotov” klasifikator bez ikakvog dodatnog treniranja na konkretnom skupu podataka. Ideja zero-shot strategije je da se modelu kroz prompt precizno objasni zadatak i striktno definišu dozvoljene izlazne klase, a zatim se od njega traži da za svaki primer vrati etiketu sentimenta. U ovom slučaju problem je dodatno pojednostavljen na tri klase (Positive, Negative, Neutral) tako što se “Irrelevant” preslikava na “Neutral”, čime se dobija konzistentna podela pogodna za poređenje sa klasičnim ML modelom.\n",
        "\n",
        "#Konsolidacija oznaka i definisanje “ground truth” vrednosti\n",
        "\n",
        "Na početku se u validacionom skupu ponovo vrši mapiranje klase “Irrelevant” na “Neutral”. Time se obezbeđuje da se evaluacija radi u istom režimu od tri klase, bez četvrte kategorije koja često predstavlja “nije o ovom entitetu”. Nakon toga se formira y_val, tj. niz stvarnih oznaka (ground truth) iz validacionog skupa, koji će se koristiti kasnije za poređenje sa predikcijama LLM-a.\n",
        "\n",
        "#Kreiranje zero-shot prompta: precizna instrukcija i kontrola izlaza\n",
        "\n",
        "Funkcija create_zero_shot_prompt(text, entity) konstruiše prompt koji ima nekoliko pažljivo osmišljenih elemenata:\n",
        "\n",
        "Uloga modela: prompt odmah postavlja model u ulogu “entity-level tweet sentiment classifier”, što je važno jer modelu daje jasan kontekst i očekivani tip odgovora.\n",
        "\n",
        "Fokus na entitet: eksplicitno se kaže da se sentiment klasifikuje “towards the entity” i navodi se konkretan entitet pod navodnicima. Ovo sprečava tipičnu grešku gde bi model klasifikovao opšti sentiment tvita, a ne odnos prema entitetu.\n",
        "\n",
        "Striktnost izlaza: prompt traži da se vrati tačno jedna od tri etikete. Ovim se modelu jasno zabranjuju objašnjenja, dodatne reči i nijansirane formulacije (“mostly positive”, “somewhat negative” i sl.).\n",
        "\n",
        "Definicija Neutral klase: pošto je “Neutral” najšira i često najproblematičnija kategorija, prompt sadrži jasna pravila kada se bira Neutral:\n",
        "\n",
        "ako je tvit nerelevantan za entitet,\n",
        "\n",
        "ako nema jasnog sentimenta,\n",
        "\n",
        "ako je informativna objava/vest,\n",
        "\n",
        "ako je pitanje bez izraženog stava.\n",
        "\n",
        "Ovo je posebno važno jer u tvitovima ima mnogo sadržaja koji nije emocionalno obojen, pa bez ovih pravila model može prečesto “halucinirati” pozitivan ili negativan ton.\n",
        "\n",
        "Na kraju prompt ubacuje konkretan tvit i ostavlja format “Label:” kao signal da je sledeće što treba da dođe samo jedna etiketa.\n",
        "\n",
        "#Inferencija nad validacionim skupom: iteracija i prikupljanje predikcija\n",
        "\n",
        "Nakon definicije prompta, pokreće se petlja kroz sve redove val_df. Koristi se tqdm kako bi se dobio progress bar i jasna povratna informacija o toku inferencije, što je bitno jer LLM pozivi po pravilu traju duže od klasične predikcije.\n",
        "\n",
        "Za svaki red:\n",
        "\n",
        "uzima se originalni tekst tvita (row['text']) i entitet (row['entity']),\n",
        "\n",
        "generiše se prompt,\n",
        "\n",
        "šalje se modelu preko query_llm(prompt),\n",
        "\n",
        "rezultat (odgovor modela) se dodaje u listu y_pred_zero_shot.\n",
        "\n",
        "Ovaj deo koda u praksi predstavlja “batch” evaluaciju, samo što se radi sekvencijalno (primer po primer), jer se pozivi vrše prema udaljenom LLM servisu.\n",
        "\n",
        "#Normalizacija izlaza: čišćenje nepredvidivih odgovora modela\n",
        "\n",
        "Iako prompt traži striktno jednu od tri etikete, LLM ponekad može vratiti:\n",
        "\n",
        "etiketu sa dodatnim rečima (“Positive sentiment”, “Label: Negative”),\n",
        "\n",
        "razlike u velikim/malim slovima,\n",
        "\n",
        "ili čak kratak komentar.\n",
        "\n",
        "Zbog toga se uvodi funkcija clean_prediction(pred) koja radi jednostavnu normalizaciju:\n",
        "\n",
        "sve spušta na mala slova,\n",
        "\n",
        "proverava da li se u izlazu pojavljuje reč “positive” ili “negative”,\n",
        "\n",
        "a ako ne prepozna ni jedno, podrazumeva “Neutral”.\n",
        "\n",
        "Ovaj “fallback” na Neutral je pragmatičan: bolje je da nejasan ili pogrešno formatiran odgovor bude tretiran kao Neutral nego da proizvede slučajnu grešku ili pogrešnu klasu koja bi narušila evaluaciju.\n",
        "\n",
        "Nakon toga se formira y_pred_zero_shot_clean, odnosno lista finalnih predikcija spremnih za poređenje sa y_val.\n",
        "\n",
        "#Evaluacija zero-shot pristupa: izveštaj i tačnost\n",
        "\n",
        "Na kraju se štampaju rezultati kroz dve ključne metrike:\n",
        "\n",
        "classification_report: daje preciznost, odziv i F1 meru za svaku klasu (Positive, Negative, Neutral). Ovo je važno jer accuracy sama po sebi može biti varljiva, naročito ako je klasa Neutral dominantna.\n",
        "\n",
        "accuracy_score: daje ukupnu tačnost kao jednu brojčanu vrednost, korisnu za brzo poređenje sa SVM baseline-om i sa few-shot pristupom."
      ],
      "metadata": {
        "id": "rUOu_baBgk3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 2. ZERO-SHOT PRISTUP (3 KLASE) ---\")\n",
        "\n",
        "val_df['sentiment'] = val_df['sentiment'].replace('Irrelevant', 'Neutral')\n",
        "y_val = val_df['sentiment']\n",
        "\n",
        "def create_zero_shot_prompt(text, entity):\n",
        "    return f\"\"\"You are an entity-level tweet sentiment classifier.\n",
        "\n",
        "Classify the sentiment of the tweet towards the entity \"{entity}\".\n",
        "\n",
        "Return EXACTLY one of these labels:\n",
        "Positive\n",
        "Negative\n",
        "Neutral\n",
        "\n",
        "Rules for Neutral:\n",
        "- If the tweet is irrelevant to the entity, return Neutral.\n",
        "- If there is no clear sentiment, return Neutral.\n",
        "- If the tweet is news/update/announcement (informative), return Neutral.\n",
        "- If the tweet is a question asking for info without an opinion, return Neutral.\n",
        "\n",
        "Tweet: {text}\n",
        "Label:\"\"\"\n",
        "\n",
        "y_pred_zero_shot = []\n",
        "for _, row in tqdm(val_df.iterrows(), total=val_df.shape[0], desc=\"Zero-shot inference\"):\n",
        "    prompt = create_zero_shot_prompt(row['text'], row['entity'])\n",
        "    response = query_llm(prompt)\n",
        "    y_pred_zero_shot.append(response)\n",
        "\n",
        "def clean_prediction(pred):\n",
        "    pred = str(pred).lower()\n",
        "    if \"positive\" in pred:\n",
        "        return \"Positive\"\n",
        "    if \"negative\" in pred:\n",
        "        return \"Negative\"\n",
        "    return \"Neutral\"\n",
        "\n",
        "y_pred_zero_shot_clean = [clean_prediction(p) for p in y_pred_zero_shot]\n",
        "\n",
        "print(\"\\nRezultati Zero-shot pristupa (3 KLASE):\")\n",
        "print(classification_report(y_val, y_pred_zero_shot_clean, labels=[\"Positive\",\"Negative\",\"Neutral\"]))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_zero_shot_clean))"
      ],
      "metadata": {
        "id": "Zi83bhvL83M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred_zero_shot_clean, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Confusion Matrix — Zero-shot (3 klase)\")\n",
        "plt.xlabel(\"Predviđeno\")\n",
        "plt.ylabel(\"Stvarno\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ySoDlaxlgnTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Few-shot Klasifikacija**\n",
        "\n",
        "Ovde biramo nekoliko primera iz trening seta i ubacujemo ih u prompt kako bismo modelu \"pokazali\" šta želimo."
      ],
      "metadata": {
        "id": "u4C78sB09KhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Few-shot pristup: “kalibrisanje” LLM-a primerima i striktno JSON formatiranje izlaza\n",
        "\n",
        "Ovaj segment koda predstavlja few-shot varijantu LLM klasifikacije sentimenta, gde se modelu ne daje samo instrukcija (kao u zero-shot režimu), već i mali skup reprezentativnih primera koji ilustruju kako treba da izgleda ulaz i kakav izlaz se očekuje. Cilj few-shot strategije je da se model “usmeri” na tačan zadatak (entity-level sentiment) i da se smanji varijabilnost u odgovoru, naročito u graničnim slučajevima (vesti, pitanja, nerelevantni tvitovi). Pored toga, ovde je poseban akcenat na robustnosti: izlaz se forsira u obliku JSON-a, a predikcije se parsiraju defensivno, uz fallback pravila.\n",
        "\n",
        "#1) Izbor few-shot primera: balans po klasama\n",
        "\n",
        "Na početku se definiše lista few_shot_examples koja sadrži ukupno šest primera, po dva za svaku klasu:\n",
        "\n",
        "Positive primeri su kratki, entuzijastični (“heck yeah”, “looking forward…”).\n",
        "\n",
        "Negative primeri imaju jasno izraženo nezadovoljstvo (“worst customer service”, “really sucks”).\n",
        "\n",
        "Neutral primeri su tipične vesti/objave (“Leak: specifications…”, “Blizzard confirms…”).\n",
        "\n",
        "Ovaj izbor nije slučajan: few-shot primeri rade kao “sidra” za model — daju mu referencu šta se smatra pozitivnim, negativnim i neutralnim u specifičnom domenu tvitova, i naročito pomažu da “Neutral” ne bude pomešan sa slabim pozitivnim/negativnim tonom.\n",
        "\n",
        "#2) Definisanje pomoćnih pravila i regularnih izraza\n",
        "\n",
        "Zatim se definišu konstante i regex obrasci:\n",
        "\n",
        "LABELS = [\"Positive\", \"Negative\", \"Neutral\"] predstavlja jedini dozvoljeni skup etiketa.\n",
        "\n",
        "_URL_RE služi za uklanjanje URL-ova (jer linkovi često ne doprinose sentimentu, a mogu “zbuniti” prompt).\n",
        "\n",
        "_JSON_RE pokušava da pronađe JSON objekat unutar odgovora modela, čak i ako model “prekrši” pravilo i doda dodatni tekst.\n",
        "\n",
        "_LABEL_RE je rezervni mehanizam: ako JSON parsiranje ne uspe, pokušava se barem izvući jedna od reči “positive/negative/neutral” iz odgovora.\n",
        "\n",
        "Ova kombinacija predstavlja tipičan “defensive parsing” pristup: kod je pripremljen za realnost da LLM ponekad ne prati format do kraja.\n",
        "\n",
        "#3) Gradnja few-shot konteksta: primeri kao mini-dataset u promptu\n",
        "\n",
        "Funkcija _strip_urls čisti URL-ove iz teksta primera, a zatim se few_shot_context formira kao blok koji spaja sve primere u isti format:\n",
        "\n",
        "Entity: ...\n",
        "\n",
        "Tweet: ...\n",
        "\n",
        "JSON: {\"label\":\"...\"}\n",
        "\n",
        "Važno je što primeri uključuju i ulaz i izlaz u tačno onom obliku koji se kasnije traži od modela. Time se modelu implicitno pokazuje: “Evo kako izgleda ispravan odgovor”.\n",
        "\n",
        "Ispis “preview” dela konteksta nije neophodan za logiku klasifikacije, ali je praktičan za debug: može se vizuelno proveriti da li su primeri formatirani ispravno i da li se slučajno ne ubacuju URL-ovi ili ružni karakteri.\n",
        "\n",
        "#4) Prompt za few-shot: striktno JSON pravilo i neutral definicija\n",
        "\n",
        "Funkcija create_few_shot_prompt(text, entity) konstruiše prompt koji je strožiji nego u zero-shot varijanti:\n",
        "\n",
        "Model dobija ulogu klasifikatora.\n",
        "\n",
        "Eksplicitno se traži da vrati samo validan JSON objekat u jednom od tri oblika:\n",
        "\n",
        "{\"label\":\"Positive\"}\n",
        "\n",
        "{\"label\":\"Negative\"}\n",
        "\n",
        "{\"label\":\"Neutral\"}\n",
        "\n",
        "Zabranjuje se markdown, backticks, komentari i bilo kakav dodatni tekst.\n",
        "\n",
        "Zatim se ponavlja definicija Neutral klase kroz jasna pravila (nerelevantno, nema stava, vesti, pitanje bez mišljenja), a ispod toga se dodaje blok Examples: koji sadrži prethodno izgrađen few_shot_context.\n",
        "\n",
        "Na kraju prompt prelazi na konkretan primer (“Now classify:”), navodi entitet i tvit iz validacionog skupa, i završava sa “JSON:” kao signal da se očekuje direktno vraćanje JSON-a.\n",
        "\n",
        "Ovaj dizajn prompta pokušava da reši dva tipična problema LLM evaluacije:\n",
        "\n",
        "model koji objašnjava umesto da klasifikuje,\n",
        "\n",
        "model koji vraća labelu u slobodnom tekstu, a ne u tačno traženom formatu.\n",
        "\n",
        "#5) Parsiranje odgovora: robustan sistem sa više slojeva\n",
        "\n",
        "Funkcija parse_prediction(response) pretvara sirov odgovor LLM-a u jednu od tri klase i radi to u više koraka:\n",
        "\n",
        "Ako je odgovor prazan, automatski se vraća “Neutral” (bezbedan fallback).\n",
        "\n",
        "Prvo se traži JSON segment pomoću _JSON_RE. Ako se pronađe, pokušava se json.loads, zatim se uzima label, normalizuje (title-case) i proverava da li je u LABELS.\n",
        "\n",
        "Ako JSON parsiranje ne uspe, pretražuje se odgovor da li sadrži reč “positive/negative/neutral” (regex _LABEL_RE).\n",
        "\n",
        "Ako ni to ne uspe, vraća se “Neutral”.\n",
        "\n",
        "Ovaj pristup obezbeđuje da evaluacija ne “pukne” zbog jednog loše formatiranog odgovora, i da rezultat uvek bude validna klasa. U eksperimentima sa LLM-ovima ovo je kritično, jer i mali procenat nepravilno formatiranih odgovora može pokvariti evaluaciju ako se ne tretira.\n",
        "\n",
        "#6) Inference petlja sa dodatnim keširanjem na nivou primera\n",
        "\n",
        "Za razliku od ranijeg query_llm keša (koji kešira po promptu), ovde se uvodi još jedan sloj keširanja:\n",
        "\n",
        "pred_cache čuva već izračunatu predikciju za par (entity, text).\n",
        "\n",
        "raw_cache čuva sirov odgovor modela za isti ključ (korisno za kasniju analizu grešaka i debug).\n",
        "\n",
        "Petlja prolazi kroz validacioni skup preko itertuples, što je efikasnije od iterrows. Za svaki (entity, text):\n",
        "\n",
        "formira se ključ (entity, text),\n",
        "\n",
        "ako je već viđen, predikcija se odmah vraća iz pred_cache,\n",
        "\n",
        "u suprotnom se pravi prompt, šalje modelu, parsira odgovor i upisuje u cache.\n",
        "\n",
        "Ovo je praktično u scenarijima gde se u dataset-u pojavljuju duplikati ili kada se eksperimenti ponavljaju: značajno se smanjuje broj LLM poziva, vreme i trošak.\n",
        "\n",
        "#7) Evaluacija i metrika “cache miss” kao indikator efikasnosti\n",
        "\n",
        "Na kraju se ispisuje:\n",
        "\n",
        "classification_report za tri klase, uz zero_division=0 da se izbegnu upozorenja u slučaju da model nijednom ne predvidi neku klasu.\n",
        "\n",
        "accuracy_score kao jednostavna ukupna metrika.\n",
        "\n",
        "“Unique prompts (cache miss)” kao odnos jedinstvenih primera prema ukupnom broju redova — indikator koliko je keš pomogao (tj. koliko duplikata ili ponovljenih upita postoji)."
      ],
      "metadata": {
        "id": "9WVmsEThhHPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_examples = [\n",
        "    # Positive\n",
        "    {\"entity\": \"Xbox(Xseries)\", \"text\": \"got a new xbox series x from best buy. heck yeah\", \"label\": \"Positive\"},\n",
        "    {\"entity\": \"Borderlands\", \"text\": \"Going to finish up volume 2 today. I've got some awesome serv... looking forward to a good stream!\", \"label\": \"Positive\"},\n",
        "\n",
        "    # Negative\n",
        "    {\"entity\": \"Amazon\", \"text\": \"@amazon probably some of the worst customer service I’ve had to deal with lately\", \"label\": \"Negative\"},\n",
        "    {\"entity\": \"Borderlands\", \"text\": \"Man Gearbox really needs to fix this dissapointing drops... Really sucks alot\", \"label\": \"Negative\"},\n",
        "\n",
        "    # Neutral\n",
        "    {\"entity\": \"Xbox(Xseries)\", \"text\": \"(Leak) Final specifications for PS5 and Xbox Series X: Two Monsters!\", \"label\": \"Neutral\"},\n",
        "    {\"entity\": \"WorldOfCraft\", \"text\": \"Blizzard confirms that World of Warcraft: Shadowlands isn't c... overclock3d.net/news/software/…\", \"label\": \"Neutral\"},\n",
        "]\n",
        "\n",
        "LABELS = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "_URL_RE = re.compile(r\"http\\S+|www\\.\\S+\", re.IGNORECASE)\n",
        "_JSON_RE = re.compile(r\"\\{.*?\\}\", re.DOTALL)\n",
        "_LABEL_RE = re.compile(r\"\\b(positive|negative|neutral)\\b\", re.IGNORECASE)\n",
        "\n",
        "def _strip_urls(s: str) -> str:\n",
        "    return _URL_RE.sub(\"\", str(s)).strip()\n",
        "\n",
        "few_shot_context = \"\\n\\n\".join(\n",
        "    f'Entity: {ex[\"entity\"]}\\n'\n",
        "    f'Tweet: {_strip_urls(ex[\"text\"])}\\n'\n",
        "    f'JSON: {{\"label\":\"{ex[\"label\"]}\"}}'\n",
        "    for ex in few_shot_examples\n",
        ")\n",
        "\n",
        "print(\"Few-shot context preview:\\n\", few_shot_context[:1200], \"...\\n\")\n",
        "\n",
        "def create_few_shot_prompt(text, entity):\n",
        "    return f\"\"\"You are an entity-level tweet sentiment classifier.\n",
        "\n",
        "Return ONLY a valid JSON object:\n",
        "{{\"label\":\"Positive\"}} OR {{\"label\":\"Negative\"}} OR {{\"label\":\"Neutral\"}}\n",
        "Do not return markdown, backticks, comments, or any extra text.\n",
        "\n",
        "Neutral means:\n",
        "- irrelevant to entity\n",
        "- no clear sentiment\n",
        "- factual news/update\n",
        "- question without opinion\n",
        "\n",
        "Examples:\n",
        "{few_shot_context}\n",
        "\n",
        "Now classify:\n",
        "Entity: {entity}\n",
        "Tweet: {text}\n",
        "\n",
        "JSON:\n",
        "\"\"\".strip()\n",
        "\n",
        "def parse_prediction(response: str) -> str:\n",
        "    txt = str(response).strip()\n",
        "    if not txt:\n",
        "        return \"Neutral\"\n",
        "\n",
        "    m = _JSON_RE.search(txt)\n",
        "    if m:\n",
        "        try:\n",
        "            payload = json.loads(m.group(0))\n",
        "            lbl = str(payload.get(\"label\", \"\")).strip().title()\n",
        "            if lbl in LABELS:\n",
        "                return lbl\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    m = _LABEL_RE.search(txt)\n",
        "    if m:\n",
        "        return m.group(1).title()\n",
        "\n",
        "    return \"Neutral\"\n",
        "\n",
        "y_val = val_df[\"sentiment\"].replace(\"Irrelevant\", \"Neutral\").tolist()\n",
        "y_pred_few_shot = []\n",
        "\n",
        "pred_cache = {}\n",
        "raw_cache = {}\n",
        "\n",
        "for entity, text in tqdm(\n",
        "    val_df[[\"entity\", \"text\"]].itertuples(index=False, name=None),\n",
        "    total=len(val_df),\n",
        "    desc=\"Few-shot (Groq JSON)\"\n",
        "):\n",
        "    key = (entity, text)\n",
        "    if key in pred_cache:\n",
        "        y_pred_few_shot.append(pred_cache[key])\n",
        "        continue\n",
        "\n",
        "    prompt = create_few_shot_prompt(text, entity)\n",
        "    response = query_llm(prompt)\n",
        "    pred = parse_prediction(response)\n",
        "\n",
        "    pred_cache[key] = pred\n",
        "    raw_cache[key] = response\n",
        "    y_pred_few_shot.append(pred)\n",
        "\n",
        "print(classification_report(y_val, y_pred_few_shot, labels=LABELS, zero_division=0))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_few_shot))\n",
        "print(f\"Unique prompts (cache miss): {len(pred_cache)} / {len(val_df)}\")"
      ],
      "metadata": {
        "id": "F6CXxcOk9M8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred_few_shot, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Confusion Matrix — Few-shot (3 klase)\")\n",
        "plt.xlabel(\"Predviđeno\")\n",
        "plt.ylabel(\"Stvarno\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vb_swfj2yCw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Poredjenje rezultata (Vizuelizacija i Tabela)**"
      ],
      "metadata": {
        "id": "7m9TvRsy9k4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"--- 6. FINALNA VIZUELIZACIJA I POREĐENJE ---\")\n",
        "\n",
        "acc_ml = accuracy_score(y_val, y_pred)\n",
        "acc_zero = accuracy_score(y_val, y_pred_zero_shot_clean)\n",
        "acc_few = accuracy_score(y_val, y_pred_few_shot)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Metod': ['Classical ML (SVM)', 'Zero-shot (LLM)', 'Few-shot (LLM)'],\n",
        "    'Accuracy': [acc_ml, acc_zero, acc_few]\n",
        "})\n",
        "\n",
        "print(\"\\nTABELA REZULTATA:\")\n",
        "print(results_df)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metod', y='Accuracy', data=results_df, palette='viridis', hue='Metod', legend=False)\n",
        "\n",
        "plt.title('Finalno poređenje tačnosti (Accuracy)', fontsize=15)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.ylabel('Tačnost', fontsize=12)\n",
        "plt.xlabel('Pristup', fontsize=12)\n",
        "\n",
        "for index, row in results_df.iterrows():\n",
        "    plt.text(index, row.Accuracy + 0.02, f\"{row.Accuracy*100:.1f}%\",\n",
        "             color='black', ha=\"center\", fontweight='bold', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nDetaljna analiza grešaka za najbolji model (SVM):\")\n",
        "labels = ['Positive', 'Negative', 'Neutral']\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 14})\n",
        "plt.title('Confusion Matrix: SVM (Pobednik)', fontsize=15)\n",
        "plt.ylabel('Stvarna klasa', fontsize=12)\n",
        "plt.xlabel('Predviđena klasa', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "004udIJ_M5lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finalna vizuelizacija i poređenje pristupa\n",
        "\n",
        "Završni segment koda služi da objedini rezultate sva tri pristupa i da ih prikaže na način koji je odmah razumljiv: prvo kao tabelu i bar-čart (poređenje tačnosti), a zatim kao konfuzionu matricu za najbolji model, kako bi se videlo gde i kako model greši. Ovaj deo je tipično “finalni slajd” u analizi: sumira performanse, potvrđuje pobednika i daje smernice za tumačenje razlika između metoda.\n",
        "\n",
        "#1) Ugradnja stvarnih rezultata i logika poređenja\n",
        "\n",
        "Pre samog plotovanja izračunavaju se tačnosti:\n",
        "\n",
        "acc_ml za klasični ML pristup (TF-IDF + linearni SVM),\n",
        "\n",
        "acc_zero za zero-shot LLM predikcije,\n",
        "\n",
        "acc_few za few-shot LLM predikcije.\n",
        "\n",
        "U konkretnom eksperimentu dobijeni su sledeći rezultati:\n",
        "\n",
        "Classical ML (SVM): 92,2% accuracy\n",
        "\n",
        "Zero-shot (LLM): 64% accuracy\n",
        "\n",
        "Few-shot (LLM): 62% accuracy\n",
        "\n",
        "Ovi brojevi se zatim smeštaju u DataFrame results_df sa dve kolone: naziv metode i accuracy. Time se dobija uredna struktura pogodna i za štampu (tabela) i za vizuelizaciju.\n",
        "\n",
        "#2) Tabela rezultata: brzi pregled pre grafika\n",
        "\n",
        "Štampanje results_df ima praktičnu ulogu: pre grafičkog prikaza postoji “čist” numerički rezime koji se lako može preneti u izveštaj ili prezentaciju. Tabela jasno pokazuje drastičnu razliku između treniranog modela i LLM pristupa bez treniranja.\n",
        "\n",
        "#3) Bar-čart: vizuelno poređenje tačnosti\n",
        "\n",
        "Zatim se crta bar-čart gde je:\n",
        "\n",
        "x-osa: metoda (SVM, zero-shot LLM, few-shot LLM),\n",
        "\n",
        "y-osa: tačnost (Accuracy).\n",
        "\n",
        "Vizuelizacija je namerno postavljena sa ylim(0, 1.1) da bi iznad stubića ostalo mesta za tekstualne anotacije.\n",
        "\n",
        "Dodatno, petlja:\n",
        "\n",
        "for index, row in results_df.iterrows():\n",
        "    plt.text(index, row.Accuracy + 0.02, f\"{row.Accuracy*100:.1f}%\")\n",
        "\n",
        "\n",
        "ispisuje procenat iznad svakog stubića (npr. 92.2%), čime grafikon postaje “samodovoljan” — posmatrač ne mora da pogađa numeričke vrednosti po visini stubića.\n",
        "\n",
        "Suština ovog prikaza je da se na prvi pogled vidi: klasični ML pristup je značajno ispred LLM pristupa u ovom zadatku.\n",
        "\n",
        "#4) Tumačenje razlika: zašto LLM pristupi zaostaju\n",
        "\n",
        "Rezultati pokazuju da su zero-shot i few-shot performanse značajno niže od SVM baseline-a. Iako se intuitivno može očekivati da few-shot poboljša rezultate u odnosu na zero-shot, ovde se desilo suprotno (62% naspram 64%). To je realan scenario i često se dešava kada:\n",
        "\n",
        "few-shot primeri nisu optimalno izabrani (premalo primera, domen nije dovoljno pokriven),\n",
        "\n",
        "model previše “imitira” strukturu primera i postane konzervativniji,\n",
        "\n",
        "prompt i JSON formatiranje uvedu dodatnu rigidnost koja dovodi do više “Neutral” fallback-ova.\n",
        "\n",
        "U praksi, LLM pristupi su ovde najviše zakazivali na neutralnoj klasi: primećeno je da su neke stvarno pozitivne poruke završavale kao Neutral. To je tipična greška kada je sentiment blag (nema jasnih pozitivnih reči, više je “implicitno zadovoljstvo”), ili kada model, zbog pravila “ako nema jasnog sentimenta → Neutral”, postane previše oprezan i radije bira Neutral nego Positive.\n",
        "\n",
        "#5) Konfuziona matrica za pobednički model (SVM)\n",
        "\n",
        "Nakon globalnog poređenja metoda, kod prelazi na dublju analizu najboljeg modela:\n",
        "\n",
        "Definišu se labels = ['Positive', 'Negative', 'Neutral'] kako bi redosled klasa bio konzistentan.\n",
        "\n",
        "Računa se konfuziona matrica:\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred, labels=labels)\n",
        "\n",
        "\n",
        "Prikazuje se heatmap gde ose znače:\n",
        "\n",
        "y-osa: stvarna klasa,\n",
        "\n",
        "x-osa: predviđena klasa.\n",
        "\n",
        "Ovakav prikaz omogućava da se vidi ne samo koliko je model tačan, već i koje greške dominiraju (npr. da li Positive često “beži” u Neutral, ili Negative u Neutral itd.). Pošto je SVM pobednik, ova matrica je praktično dokaz da model ne samo da ima visoku tačnost, već i da je greška raspoređena na prihvatljiv način.\n",
        "\n",
        "#6) Zaključak ovog segmenta\n",
        "\n",
        "Ovaj deo rada zatvara eksperiment na dva nivoa:\n",
        "\n",
        "Makro nivo (bar-čart + tabela): jasno pokazuje da je trenirani TF-IDF + SVM model ubedljivo najbolji po accuracy (92,2%), dok LLM zero-shot i few-shot ostaju na ~64% i ~62%.\n",
        "\n",
        "Mikro nivo (confusion matrix): pruža uvid u tipične greške najboljeg modela i služi kao osnova za interpretaciju.\n",
        "\n",
        "Istovremeno, komentarisana slabost LLM pristupa (“guranje” pozitivnih u neutralnu) ukazuje na ključni problem: bez finog treniranja ili bolje kalibracije, LLM u ovom zadatku često igra na sigurno i bira Neutral, što direktno ruši recall za Positive klasu i obara ukupnu tačnost."
      ],
      "metadata": {
        "id": "AKoqbp1Sh63L"
      }
    }
  ]
}