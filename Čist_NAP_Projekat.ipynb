{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwU9Ph4MnOJ7E8a6iCoLfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksasekulicfon/Napredna-analiza-podataka/blob/main/%C4%8Cist_NAP_Projekat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalacija biblioteka i UÄitavanje podataka\n",
        "\n",
        "Ovaj blok instalira potrebne biblioteke i uÄitava CSV fajlove."
      ],
      "metadata": {
        "id": "GuTPyAJH7yx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6rGn9Qo7q9n"
      },
      "outputs": [],
      "source": [
        "# 1. Instalacija i UÄitavanje\n",
        "!pip install pandas scikit-learn transformers accelerate torch matplotlib seaborn -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "from sklearn.pipeline import Pipeline\n",
        "import re\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"PodeÅ¡en ureÄ‘aj: {device}\")\n",
        "\n",
        "# UÄitavanje podataka\n",
        "columns = ['id', 'entity', 'sentiment', 'text']\n",
        "train_df = pd.read_csv('twitter_training.csv', names=columns, header=None).dropna(subset=['text'])\n",
        "val_df = pd.read_csv('twitter_validation.csv', names=columns, header=None).dropna(subset=['text'])\n",
        "\n",
        "# Definisanje ulaza (Entity + Tweet)\n",
        "# Pravimo novu kolonu koja spaja entitet i tekst kako je traÅ¾eno\n",
        "train_df['input_text'] = \"entity: \" + train_df['entity'] + \" | tweet: \" + train_df['text']\n",
        "val_df['input_text'] = \"entity: \" + val_df['entity'] + \" | tweet: \" + val_df['text']\n",
        "\n",
        "print(\"Primer ulaznog podatka:\", train_df['input_text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ObrazloÅ¾enje koda i metodologije (1. Deo: Inicijalizacija)**\n",
        "## 1. Priprema okruÅ¾enja i uvoz biblioteka\n",
        "\n",
        " Prvi korak u mom istraÅ¾ivanju bio je uspostavljanje stabilnog okruÅ¾enja koje podrÅ¾ava hibridni pristup â€“ kombinaciju klasiÄnog maÅ¡inskog uÄenja i modernih LLM modela.\n",
        "\n",
        "Instalacija (!pip install...): PoÅ¡to koristim Google Colab, morao sam da instaliram specifiÄne biblioteke koje nisu \"pre-installed\", pre svega transformers i accelerate za rad sa Hugging Face modelima, jer planiram da koristim FLAN-T5 za Zero-shot i Few-shot eksperimente.\n",
        "\n",
        "Importovanje alata:\n",
        "\n",
        "Uvezao sam pandas i numpy kao osnovne alate za manipulaciju tabelarnim podacima i numeriÄke operacije.\n",
        "\n",
        "Za vizuelizaciju rezultata (posebno matrice konfuzije na kraju) koristim matplotlib i seaborn.\n",
        "\n",
        "KljuÄni deo za prvi eksperiment je sklearn (Scikit-learn). Odavde sam uvezao sve Å¡to mi je potrebno za izgradnju i evaluaciju klasiÄnog modela: TfidfVectorizer za pretvaranje teksta u brojeve, LogisticRegression (kasnije zamenjen sa SVM radi bolje taÄnosti) kao klasifikator, i GridSearchCV za sistematsku optimizaciju hiper-parametara.\n",
        "\n",
        "Za napredniji deo rada, uvezao sam transformers klase (AutoTokenizer, AutoModelForSeq2SeqLM) koje mi omoguÄ‡avaju da uÄitam i \"razgovaram\" sa velikim jeziÄkim modelom.\n",
        "\n",
        "## 2. UÄitavanje i inicijalno ÄiÅ¡Ä‡enje podataka\n",
        "\n",
        "Podatke sam uÄitao direktno iz CSV fajlova (twitter_training.csv i twitter_validation.csv).\n",
        "\n",
        "Imenovanje kolona: Primetio sam da originalni fajlovi nemaju zaglavlje (header), pa sam ruÄno definisao nazive kolona (id, entity, sentiment, text) kako bih mogao jasno da referenciram podatke.\n",
        "\n",
        "Uklanjanje praznih vrednosti: Odmah sam primenio .dropna(subset=['text']) jer dataset sadrÅ¾i nekoliko oÅ¡teÄ‡enih redova gde nedostaje tekst tvita. Takvi podaci su beskorisni za NLP zadatak i samo bi izazvali greÅ¡ke u kodu.\n",
        "\n",
        "## 3. InÅ¾enjering karakteristika (Feature Engineering)\n",
        "\n",
        "Ovo je najvaÅ¾niji metodoloÅ¡ki korak u ovoj fazi.\n",
        "\n",
        "Problem: Sentiment tvita Äesto zavisi od konteksta entiteta. ReÄ \"lag\" je negativna ako priÄamo o igrici (npr. Overwatch), ali moÅ¾e biti neutralna u drugom kontekstu. Ako modelu dam samo tekst tvita, on gubi informaciju o tome na Å¡ta se sentiment odnosi.\n",
        "\n",
        "ReÅ¡enje (Entity + Tweet): Zato sam, u skladu sa specifikacijom zadatka, kreirao novu kolonu input_text.\n",
        "\n",
        "Koristio sam konkatenaciju stringova da spojim entitet i sadrÅ¾aj poruke u format: \"entity: [Ime Entiteta] | tweet: [Tekst Tvita]\". Ovim formatom \"forsiram\" model (bilo da je ML ili LLM) da uvek uzme u obzir i entitet pre nego Å¡to donese odluku o sentimentu. Ovo simulira kontekstualno razumevanje koje je kljuÄno za Entity-Level Sentiment Analysis."
      ],
      "metadata": {
        "id": "cbcxWenjDpPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pristup 1: KlasiÄni Machine Learning (ML)\n",
        "\n",
        "Ovo je \"baseline\" model. Koristimo TF-IDF za pretvaranje teksta u brojeve i LogistiÄku Regresiju za klasifikaciju."
      ],
      "metadata": {
        "id": "9gEvIz7h8Qai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uklanjanje praznih redova\n",
        "train_df = train_df.dropna(subset=['text'])\n",
        "val_df = val_df.dropna(subset=['text'])\n",
        "\n",
        "# Svodimo problem na 3 klase: Positive, Negative, Neutral\n",
        "train_df['sentiment'] = train_df['sentiment'].replace('Irrelevant', 'Neutral')\n",
        "val_df['sentiment'] = val_df['sentiment'].replace('Irrelevant', 'Neutral')\n",
        "\n",
        "# --- UKLANJANJE DUPLIKATA ---\n",
        "# Dataset ima mnogo dupliranih tvitova koji veÅ¡taÄki diÅ¾u accuracy na treningu, a spuÅ¡taju na testu\n",
        "initial_len = len(train_df)\n",
        "train_df = train_df.drop_duplicates(subset=['text', 'sentiment'])\n",
        "print(f\"Uklonjeno {initial_len - len(train_df)} duplikata iz trening seta.\")\n",
        "\n",
        "# 2. ÄŒIÅ Ä†ENJE TEKSTA\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+', '', text) # Ukloni linkove\n",
        "    text = re.sub(r'@\\w+', '', text)    # Ukloni @mentions (imena korisnika)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Ostavi samo slova\n",
        "    return text\n",
        "\n",
        "# Primenjujemo ÄiÅ¡Ä‡enje\n",
        "train_df['clean_text'] = train_df['text'].apply(clean_text)\n",
        "val_df['clean_text'] = val_df['text'].apply(clean_text)\n",
        "\n",
        "# Formiranje ulaza (Entity + Clean Text)\n",
        "train_df['input_text'] = \"entity: \" + train_df['entity'] + \" | tweet: \" + train_df['clean_text']\n",
        "val_df['input_text'] = \"entity: \" + val_df['entity'] + \" | tweet: \" + val_df['clean_text']\n",
        "\n",
        "print(\"Primer oÄiÅ¡Ä‡enog ulaza:\", train_df['input_text'].iloc[0])\n",
        "\n",
        "# 3. KREIRANJE MOÄ†NOG PIPELINE-a\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=15000,     # PoveÄ‡ano da uhvati viÅ¡e reÄi\n",
        "        ngram_range=(1, 2),     # Unigrami i Bigrami (hvata kontekst \"not good\")\n",
        "        stop_words='english'    # Uklanja reÄi kao \"the\", \"is\", \"at\"\n",
        "    )),\n",
        "    ('clf', LogisticRegression(\n",
        "        solver='liblinear',     # Brz solver za tekst\n",
        "        max_iter=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 4. GRID SEARCH NA CELOM SETU (TraÅ¾enje najboljih hiper-parametara)\n",
        "param_grid = {\n",
        "    'clf__C': [0.1, 1, 5, 10],            # JaÄina regularizacije\n",
        "    'clf__class_weight': [None, 'balanced'] # Da li da pojaÄa manjinske klase\n",
        "}\n",
        "\n",
        "print(\"\\nPokreÄ‡em optimizaciju modela (Grid Search)...\")\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_df['input_text'], train_df['sentiment'])\n",
        "\n",
        "print(f\"Najbolji parametri: {grid_search.best_params_}\")\n",
        "\n",
        "# 5. FINALNA EVALUACIJA\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(val_df['input_text'])\n",
        "y_val = val_df['sentiment']\n",
        "\n",
        "# Ispis rezultata\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n--- MAKSIMALNA POSTIGNUTA TAÄŒNOST (3 KLASE): {acc:.4f} ---\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Matrica konfuzije\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_val, y_pred, labels=['Positive', 'Negative', 'Neutral'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Pos', 'Neg', 'Neu'],\n",
        "            yticklabels=['Pos', 'Neg', 'Neu'])\n",
        "plt.title('Confusion Matrix (Optimized 3-Class ML)')\n",
        "plt.ylabel('Stvarno')\n",
        "plt.xlabel('PredviÄ‘eno')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "phECGWDP8Z4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **ObrazloÅ¾enje koda i metodologije (2. Deo: KlasiÄan ML pristup)**\n",
        "## 1. Redukcija problema i ÄiÅ¡Ä‡enje dataset-a\n",
        "\n",
        " Pre nego Å¡to sam pristupio treniranju, morao sam da reÅ¡im strukturalne probleme u podacima.\n",
        "\n",
        "Spajanje klasa (3 umesto 4): U skladu sa literaturom i logikom zadatka, klase Irrelevant i Neutral nose istu informaciju â€“ odsustvo jasnog pozitivnog ili negativnog stava. Zato sam ih spojio u jednu klasu (Neutral). Ovo pojednostavljuje problem modelu i uklanja sivu zonu gde se te dve klase preklapaju.\n",
        "\n",
        "Eliminacija curenja podataka (Data Leakage): Primetio sam da dataset sadrÅ¾i identiÄne tvitove koji se ponavljaju viÅ¡e puta (duplikati). Ako bih ih ostavio, model bi na validaciji \"pogaÄ‘ao\" tvitove koje je veÄ‡ video u treningu, Å¡to bi dalo laÅ¾no visoku taÄnost. Funkcijom drop_duplicates osigurao sam da je evaluacija poÅ¡tena i realna.\n",
        "\n",
        "## 2. Agresivno ÄiÅ¡Ä‡enje teksta (Preprocessing)\n",
        "\n",
        "Definisao sam funkciju clean_text sa ciljem da maksimalno normalizujem ulaz.\n",
        "\n",
        "Koristio sam regularne izraze (re) da uklonim linkove i @mentions jer oni obiÄno ne nose sentiment (npr. link ka slici ne govori da li je tvit sreÄ‡an ili tuÅ¾an).\n",
        "\n",
        "TakoÄ‘e, zadrÅ¾ao sam samo slova ([^a-zA-Z\\s]), uklanjajuÄ‡i brojeve i specijalne karaktere, kako bih smanjio dimenzionalnost vektorskog prostora i fokusirao model iskljuÄivo na reÄi.\n",
        "\n",
        "## 3. Vektorizacija i Pipeline\n",
        "\n",
        "Za pretvaranje teksta u brojeve odabrao sam TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "UkljuÄio sam bigrame (ngram_range=(1, 2)), Å¡to znaÄi da model ne gleda samo reÄ \"good\", veÄ‡ i parove reÄi kao \"very good\" ili \"not good\", pokuÅ¡avajuÄ‡i da uhvati osnovni kontekst.\n",
        "\n",
        "Koristio sam ugraÄ‘enu listu stop_words='english' da izbacim Äeste reÄi poput \"the\", \"is\", \"at\", smatrajuÄ‡i ih Å¡umom koji ne doprinosi klasifikaciji.\n",
        "\n",
        "Sve sam to spakovao u Pipeline zajedno sa LogistiÄkom regresijom (solver='liblinear'), koja je standardan i brz algoritam za tekstualnu klasifikaciju.\n",
        "\n",
        "## 4. Optimizacija hiper-parametara (Grid Search)\n",
        "\n",
        "Nisam Å¾eleo da nagaÄ‘am parametre modela. Umesto toga, pokrenuo sam GridSearchCV na celom trening skupu.\n",
        "\n",
        "Ovaj proces je automatski testirao razliÄite jaÄine regularizacije (C) i opcije za balansiranje klasa (class_weight), traÅ¾eÄ‡i matematiÄki optimalnu kombinaciju koja daje najbolji rezultat na unakrsnoj validaciji (Cross-Validation).\n",
        "\n",
        "## KRITIÄŒKI OSVRT: ZaÅ¡to ovaj pristup moÅ¾e dati LOÅ IJU taÄnost?\n",
        "\n",
        "Ovaj pristup u sebi krije tri fatalne greÅ¡ke za analizu sentimenta na Twitteru, koje direktno obaraju taÄnost (accuracy):\n",
        "\n",
        "Problem \"Stop-reÄi\" (NajveÄ‡i krivac): Koristio sam stop_words='english'. Ova lista automatski briÅ¡e reÄi kao Å¡to su \"not\", \"no\", \"never\".\n",
        "\n",
        "Posledica: ReÄenica \"The game is not good\" postaje \"game good\". Model ovo vidi kao Pozitivno, a zapravo je Negativno. Brisanje negacija uniÅ¡tava sposobnost modela da prepozna suprotna znaÄenja.\n",
        "\n",
        "Gubitak interpunkcije i emotikona: Funkcija za ÄiÅ¡Ä‡enje briÅ¡e sve Å¡to nije slovo ([^a-zA-Z\\s]).\n",
        "\n",
        "Posledica: Na Twitteru su emotikoni (ğŸ˜¡, â¤ï¸, ğŸ‘) i interpunkcija (???, !!!) Äesto jaÄi signal sentimenta od samih reÄi. Tvit koji sadrÅ¾i samo sliku i \"ğŸ˜¡\" biÄ‡e prazan string za ovaj model. Model je \"oslepeo\" za kljuÄne vizuelne signale emocija.\n",
        "\n",
        "OgraniÄenja modela: Iako je LogistiÄka regresija solidna, Linear SVM (Support Vector Machine) se u praksi pokazuje znatno boljim za tekstualne podatke visoke dimenzionalnosti jer bolje pronalazi granicu (marginu) izmeÄ‘u klasa. TakoÄ‘e, parametri max_features=15000 mogu biti preniski za bogat reÄnik gejming zajednice. Tako da Ä‡emo ispod ove greÅ¡ke \"ispraviti\"."
      ],
      "metadata": {
        "id": "X6J27RNIEt5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC # JAÄŒI MODEL\n",
        "\n",
        "# 2. ÄŒIÅ Ä†ENJE TEKSTA (ÄŒuvamo bitne signale)\n",
        "def smart_clean_text(text):\n",
        "    text = str(text) # Ne spuÅ¡tamo odmah na lower() da saÄuvamo \"BAD\" vs \"bad\" ako Å¾elimo, ali TF-IDF Ä‡e to srediti\n",
        "    text = re.sub(r'http\\S+', '', text) # BriÅ¡emo linkove (oni su Å¡um)\n",
        "    text = re.sub(r'@\\w+', '', text)    # BriÅ¡emo username-ove (Å¡um)\n",
        "    # BriÅ¡emo samo specifiÄne karaktere koji smetaju, ali ostavljamo ! ? i emodÅ¾ije (ako ih ima kao tekst)\n",
        "    # Za prost ML, ipak Ä‡emo svesti na slova ali Ä‡emo biti paÅ¾ljiviji\n",
        "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text) # Ostavljamo ! i ?\n",
        "    text = text.lower() # Ipak mala slova radi normalizacije\n",
        "    return text\n",
        "\n",
        "# Primenjujemo novo ÄiÅ¡Ä‡enje\n",
        "train_df['clean_text'] = train_df['text'].apply(smart_clean_text)\n",
        "val_df['clean_text'] = val_df['text'].apply(smart_clean_text)\n",
        "\n",
        "# Formiranje ulaza\n",
        "train_df['input_text'] = \"entity: \" + train_df['entity'] + \" | tweet: \" + train_df['clean_text']\n",
        "val_df['input_text'] = \"entity: \" + val_df['entity'] + \" | tweet: \" + val_df['clean_text']\n",
        "\n",
        "# 3. NOVI PIPELINE (SVM + Custom Stopwords)\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=25000,     # PoveÄ‡avamo reÄnik\n",
        "        ngram_range=(1, 3),     # Dodajemo i TRIGRAME (\"not good at\")\n",
        "        # Ne koristimo stop_words='english' jer briÅ¡e \"not\"!\n",
        "        # Umesto toga, koristiÄ‡emo min_df da izbacimo reÄi koje se retko javljaju\n",
        "        min_df=2,\n",
        "        max_df=0.9\n",
        "    )),\n",
        "    ('clf', LinearSVC(          # Menjamo LogReg sa SVM\n",
        "        random_state=42,\n",
        "        dual='auto',            # Automatski bira najbolji algoritam\n",
        "        max_iter=5000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 4. GRID SEARCH ZA SVM\n",
        "param_grid = {\n",
        "    'clf__C': [0.1, 1, 10],             # Regularizacija za SVM\n",
        "    'clf__class_weight': [None, 'balanced'],\n",
        "    'tfidf__sublinear_tf': [True, False] # Logaritamsko skaliranje frekvencija (Äesto pomaÅ¾e)\n",
        "}\n",
        "\n",
        "print(\"\\nPokreÄ‡em optimizaciju SVM modela (Grid Search)...\")\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_df['input_text'], train_df['sentiment'])\n",
        "\n",
        "print(f\"Najbolji parametri: {grid_search.best_params_}\")\n",
        "\n",
        "# 5. EVALUACIJA\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(val_df['input_text'])\n",
        "y_val = val_df['sentiment']\n",
        "\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n--- MAKSIMALNA TAÄŒNOST SA SVM: {acc:.4f} ---\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# Matrica konfuzije\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_val, y_pred, labels=['Positive', 'Negative', 'Neutral'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Pos', 'Neg', 'Neu'],\n",
        "            yticklabels=['Pos', 'Neg', 'Neu'])\n",
        "plt.title('Confusion Matrix (SVM Model)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2rlnUWqYBpTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ObrazloÅ¾enje napredne metodologije (Optimizovani ML pristup)**\n",
        "## 1. \"Pametno\" ÄiÅ¡Ä‡enje teksta (Smart Preprocessing)\n",
        "\n",
        " U prethodnom pokuÅ¡aju sam bio previÅ¡e agresivan sa ÄiÅ¡Ä‡enjem i time \"osakatio\" podatke. Shvatio sam da brisanje interpunkcije briÅ¡e i emociju.\n",
        "\n",
        "OÄuvanje signala sentimenta: U funkciji smart_clean_text, promenio sam regex tako da zadrÅ¾ava znakove ! i ?.\n",
        "\n",
        "ZaÅ¡to? ReÄenica \"That was bad\" je negativna, ali \"That was bad???\" moÅ¾e biti iznenaÄ‘enje ili neverica. Tvit \"We won!\" nosi jaÄi pozitivan signal od \"we won\". Ovi znaci su vitalni za Twitter komunikaciju.\n",
        "\n",
        "Normalizacija: I dalje spuÅ¡tam slova na mala (lower()) i briÅ¡em linkove, jer Å¾elim da model uÄi reÄi, a ne URL adrese.\n",
        "\n",
        "## 2. Napredna vektorizacija*\n",
        "\n",
        "Ovde sam napravio najradikalnije promene kako bih modelu dao \"bolje naoÄare\" za Äitanje teksta.\n",
        "\n",
        "ProÅ¡iren reÄnik (max_features=25000): PoveÄ‡ao sam kapacitet modela da vidi reÄ‘e reÄi koje su specifiÄne za gejming Å¾argon.\n",
        "\n",
        "UvoÄ‘enje Trigrama (ngram_range=(1, 3)): Ovo je kljuÄno. Model sada ne vidi samo reÄi (\"game\", \"bad\"), veÄ‡ i fraze od tri reÄi (\"game is not\", \"not bad at\"). Ovo mu omoguÄ‡ava da razume kontekst koji prethodni model nije video.\n",
        "\n",
        "ZadrÅ¾avanje \"Stop-reÄi\": Svesno sam izbacio stop_words='english'.\n",
        "\n",
        "Logika: U sentiment analizi, reÄi kao Å¡to su \"not\", \"no\", \"but\" nisu Å¡um â€“ one su presudne! One menjaju znaÄenje iz korena (npr. \"like\" vs \"do not like\"). Umesto toga, koristio sam min_df=2 da statistiÄki izbacim samo greÅ¡ke u kucanju koje se javljaju jednom i nikad viÅ¡e.\n",
        "\n",
        "## 3. Promena algoritma: Ulazak SVM-a\n",
        "\n",
        "Zamenio sam LogistiÄku regresiju sa LinearSVC (Support Vector Machine).\n",
        "\n",
        "ZaÅ¡to SVM? Dok LogistiÄka regresija pokuÅ¡ava da naÄ‘e verovatnoÄ‡u, SVM geometrijski traÅ¾i \"najÅ¡iru ulicu\" (marginu) koja razdvaja pozitivne od negativnih primera. U radu sa tekstom, koji ima na hiljade dimenzija (reÄi), SVM je istorijski dokazan kao najmoÄ‡niji \"klasiÄan\" algoritam jer je izuzetno robustan na Å¡um i teÅ¾e ga je zbuniti sliÄnim primerima.\n",
        "\n",
        "## 4. Fino podeÅ¡avanje (Grid Search)\n",
        "\n",
        "Dodao sam i sublinear_tf=True u pretragu. Ovo je tehnika koja logaritamski \"spljoÅ¡ti\" brojanje reÄi (da reÄ koja se ponovi 50 puta ne bude 50 puta vaÅ¾nija od one koja se javi jednom, veÄ‡ samo malo vaÅ¾nija). To Äesto drastiÄno popravlja taÄnost, Å¡to se u ovom sluÄaju i desilo.\n",
        "\n",
        "ANALIZA USPEHA: ZaÅ¡to je ovaj model \"razbio\" (High Accuracy)?\n",
        "Razlog za skok taÄnosti sa proseÄnih ~75% na vrhunskih ~90%+:\n",
        "\n",
        "Efekat \"Negacije\": Prethodni model je bio \"glup\" za negacije jer smo brisali stop-reÄi.\n",
        "\n",
        "Stari model: Vidi \"not happy\" -> obriÅ¡e \"not\" -> ostane \"happy\" -> GreÅ¡ka (Positive).\n",
        "\n",
        "Novi model: Vidi \"not happy\" -> Äuva frazu -> prepoznaje trigram \"not happy\" -> TaÄno (Negative).\n",
        "\n",
        "MoÄ‡ SVM-a: SVM (LinearSVC) je mnogo bolji u povlaÄenju oÅ¡trih granica. Tamo gde je LogistiÄka regresija bila nesigurna (npr. verovatnoÄ‡a 51% vs 49%), SVM je naÅ¡ao jasnu matematiÄku granicu i ispravno klasifikovao teÅ¡ke primere.\n",
        "\n",
        "Kontekstualna dubina: KoriÅ¡Ä‡enjem trigrama (3 reÄi u nizu) model je poÄeo da hvata kratke frazeoloÅ¡ke izraze (\"waste of money\", \"best game ever\"), umesto da gleda reÄi kao nepovezanu vreÄ‡u (Bag of Words).\n",
        "\n",
        "ZakljuÄak: Ovaj pristup pokazuje da kod klasiÄnog maÅ¡inskog uÄenja nije uvek potrebno preÄ‡i na neuronske mreÅ¾e da bi se dobio vrhunski rezultat â€“ Äesto je dovoljno samo pametnije pripremiti podatke i odabrati algoritam koji poÅ¡tuje specifiÄnosti jezika (negacije i fraze)."
      ],
      "metadata": {
        "id": "E9Q3YrIRKKdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Priprema za LLM (Large Language Model)**\n",
        "\n",
        "Ovde uÄitavamo model google/flan-t5-base. On je besplatan, staje u Colab memoriju i odliÄan je za praÄ‡enje instrukcija (Instruction Tuned)."
      ],
      "metadata": {
        "id": "VqHUJsav8fHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- UÄitavanje LLM Modela (FLAN-T5) ---\")\n",
        "\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "def query_llm(prompt):\n",
        "    \"\"\"Funkcija koja Å¡alje prompt modelu i vraÄ‡a tekstualni odgovor.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Model uÄitan!\")"
      ],
      "metadata": {
        "id": "Qp8Kx-PH8pgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ObrazloÅ¾enje koda i metodologije (3. Deo: LLM Inicijalizacija)**\n",
        "## 1. Izbor Modela: Prelazak na \"Large\" varijantu\n",
        "\n",
        "Za potrebe Zero-shot i Few-shot klasifikacije, odluÄio sam se za google/flan-t5-large.\n",
        "\n",
        "ZaÅ¡to FLAN-T5? Ovo nije obiÄan jeziÄki model (kao GPT-2). \"FLAN\" (Finetuned Language Net) znaÄi da je model dodatno treniran na instrukcijama. On zna Å¡ta znaÄi \"Classify this text\", Å¡to je kljuÄno za moj rad jer mu neÄ‡u davati hiljade primera za trening (kao kod ML modela), veÄ‡ Ä‡u mu samo zadavati komande na engleskom jeziku.\n",
        "\n",
        "ZaÅ¡to \"Large\"? Iako \"Base\" verzija troÅ¡i manje memorije, preÅ¡ao sam na \"Large\" (cca 780M parametara) jer ona poseduje znatno bolju sposobnost rezonovanja i praÄ‡enja sloÅ¾enijih promptova, Å¡to je neophodno za razumevanje suptilnog sentimenta u tvitovima.\n",
        "\n",
        "## 2. Arhitektura: Seq2Seq (Encoder-Decoder)\n",
        "\n",
        "Koristim klasu AutoModelForSeq2SeqLM.\n",
        "\n",
        "T5 (Text-to-Text Transfer Transformer) funkcioniÅ¡e po principu Sequence-to-Sequence. To znaÄi da on svaki zadatak posmatra kao prevod: \"tekst ulaza\" (tvit + instrukcija) se prevodi u \"tekst izlaza\" (sentiment labelu). Ovo je idealno za klasifikaciju gde oÄekujem taÄan tekstualni odgovor (\"Positive\", \"Negative\").\n",
        "\n",
        "## 3. Optimizacija inferencije (query_llm funkcija)\n",
        "\n",
        "Kreirao sam omotaÄ funkciju query_llm koja apstrahuje komunikaciju sa modelom, uz nekoliko kljuÄnih inÅ¾enjerskih odluka:\n",
        "\n",
        "Upravljanje memorijom (with torch.no_grad()): Ovo je najvaÅ¾nija linija za stabilnost u Colabu. PoÅ¡to model ne treniram (ne radim backpropagation), iskljuÄio sam raÄunanje gradijenata. Ovo drastiÄno smanjuje potroÅ¡nju VRAM-a (video memorije) i ubrzava generisanje odgovora. Bez ovoga, Colab bi se verovatno sruÅ¡io (\"OOM Error\"), Å¡to se ranije dosta puta deÅ¡avalo nakon samo nekoliko reÄenica.\n",
        "\n",
        "OgraniÄenje ulaza (truncation=True, max_length=512): T5 model ima fiksni \"prozor\" paÅ¾nje od 512 tokena. Svaki tekst duÅ¾i od toga bi izazvao greÅ¡ku. Ovim parametrom osiguravam da se predugaÄki tvitovi automatski skrate na bezbednu duÅ¾inu, ÄuvajuÄ‡i poÄetak teksta (gde je obiÄno instrukcija).\n",
        "\n",
        "Kontrola izlaza (max_new_tokens=10): Meni ne treba da model napiÅ¡e esej o tvitu. Treba mi samo jedna reÄ (Sentiment). Postavljanjem limita na 10 novih tokena, spreÄavam model da \"halucinira\" ili nastavlja tekst bespotrebno, Äime dodatno ubrzavam proces.\n",
        "\n",
        "## Rezime\n",
        "\n",
        "Ovim blokom koda sam pripremio moÄ‡an, instrukcijski podeÅ¡en model i optimizovao ga da radi efikasno u ograniÄenom hardverskom okruÅ¾enju, fokusirajuÄ‡i se iskljuÄivo na inferenciju (predikciju), a ne na trening."
      ],
      "metadata": {
        "id": "88tgNVKjLjOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Pristup 2: Zero-shot Klasifikacija\n",
        "\n",
        "PitaÄ‡emo model direktno da klasifikuje sentiment bez davanja primera."
      ],
      "metadata": {
        "id": "STnX-t5P8yY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 2. ZERO-SHOT PRISTUP ---\")\n",
        "\n",
        "# Funkcija za kreiranje Zero-shot prompta\n",
        "def create_zero_shot_prompt(text, entity):\n",
        "    return f\"\"\"Classify the sentiment of the following tweet towards the entity '{entity}'.\n",
        "Options: Positive, Negative, Neutral, Irrelevant.\n",
        "\n",
        "Tweet: {text}\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "# PokreÄ‡emo predikciju na validacionom setu (ovo moÅ¾e potrajati par minuta)\n",
        "y_pred_zero_shot = []\n",
        "# Koristimo tqdm za progress bar\n",
        "for index, row in tqdm(val_df.iterrows(), total=val_df.shape[0], desc=\"Zero-shot inference\"):\n",
        "    prompt = create_zero_shot_prompt(row['text'], row['entity'])\n",
        "    response = query_llm(prompt)\n",
        "    y_pred_zero_shot.append(response)\n",
        "\n",
        "# ÄŒiÅ¡Ä‡enje izlaza (LLM nekad doda taÄku ili malo slovo, moramo standardizovati)\n",
        "# Mapiramo sirovi tekst u klase koje imamo u datasetu\n",
        "def clean_prediction(pred):\n",
        "    pred = pred.lower()\n",
        "    if \"positive\" in pred: return \"Positive\"\n",
        "    if \"negative\" in pred: return \"Negative\"\n",
        "    if \"neutral\" in pred: return \"Neutral\"\n",
        "    if \"irrelevant\" in pred: return \"Irrelevant\"\n",
        "    return \"Neutral\" # Fallback ako model izbaci neÅ¡to Äudno\n",
        "\n",
        "y_pred_zero_shot_clean = [clean_prediction(p) for p in y_pred_zero_shot]\n",
        "\n",
        "# Evaluacija\n",
        "print(\"\\nRezultati Zero-shot pristupa:\")\n",
        "print(classification_report(y_val, y_pred_zero_shot_clean))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_zero_shot_clean))"
      ],
      "metadata": {
        "id": "Zi83bhvL83M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ObrazloÅ¾enje koda i metodologije (Zero-Shot Pristup)**\n",
        "**1. Dizajn Prompta (Prompt Engineering)**\n",
        "\n",
        "U funkciji create_zero_shot_prompt definisao sam instrukciju koja simulira kako Äovek zadaje zadatak.\n",
        "\n",
        "Struktura: Nisam samo ubacio tekst tvita. Jasno sam definisao ulogu modela (\"Classify the sentiment...\"), naveo ciljni entitet (jer sentiment zavisi od njega) i eksplicitno nabrojao opcije (Positive, Negative, Neutral, Irrelevant).\n",
        "\n",
        "Cilj: Ovim \"uokvirujem\" prostor odgovora. Bez ponuÄ‘enih opcija, model bi mogao da odgovori sa \"It's a happy tweet\" ili \"The user is angry\", Å¡to bi bilo nemoguÄ‡e automatski oceniti.\n",
        "\n",
        "**2. Proces Inferencije (Petlja predikcije)**\n",
        "\n",
        "Za razliku od ML modela koji moÅ¾e da predvidi 1000 tvitova u milisekundi, LLM je sporiji.\n",
        "\n",
        "Koristio sam petlju (for loop) sa tqdm bibliotekom da bih imao vizuelni prikaz napretka (progress bar), jer obrada 1000 tvitova na GPU-u traje par minuta.\n",
        "\n",
        "Svaki tvit i entitet se pakuju u prompt, Å¡alju modelu, a odgovor se Äuva u listi.\n",
        "\n",
        "**3. \"Sanitizacija\" Izlaza (clean_prediction)**\n",
        "\n",
        "Ovo je neophodan korak u radu sa generativnim modelima.\n",
        "\n",
        "Problem: ÄŒak i kad mu kaÅ¾em \"odgovori samo jednom reÄju\", FLAN-T5 nekad moÅ¾e da odgovori sa \"The sentiment is Positive.\" ili \"positive.\".\n",
        "\n",
        "ReÅ¡enje: Moja funkcija clean_prediction traÅ¾i kljuÄne reÄi u odgovoru i mapira ih na fiksne labele. Ako model poÄne da \"halucinira\" ili da neodreÄ‘en odgovor, funkcija vraÄ‡a \"Neutral\" kao fallback opciju, Äime spreÄavam pucanje koda pri evaluaciji.\n",
        "\n",
        "INTERPRETACIJA REZULTATA (Accuracy: 56.7%)\n",
        "\n",
        "Rezultat od 56.7% je znatno niÅ¾i od optimizovanog ML modela (~91%), ali je i dalje bolji od nasumiÄnog pogaÄ‘anja (33%). Evo detaljne analize zaÅ¡to se ovo desilo:\n",
        "\n",
        "## 1. Problem generalizacije vs. SpecifiÄnosti domena\n",
        "\n",
        "ML Model (91%) je video 70.000 primera iz ovog konkretnog dataseta. NauÄio je taÄno kako gejmeri govore (npr. da je reÄ \"nerf\" negativna za lika u igrici).\n",
        "\n",
        "Zero-shot LLM (56%) koristi opÅ¡te znanje sa interneta. On moÅ¾da ne razume specifiÄan gejming Å¾argon ili sarkazam bez konteksta. Za njega je ovo \"hladan start\".\n",
        "\n",
        "## 2. \"Ahilova peta\" â€“ Klasa Neutral (Recall: 0.35)\n",
        "\n",
        " PogledaÄ‡emo Recall za klasu Neutral â€“ iznosi samo 0.35. To znaÄi da je model prepoznao samo 35% stvarno neutralnih tvitova. Gde je greÅ¡io?\n",
        "\n",
        "Razlog: U promptu sam mu ponudio opciju \"Irrelevant\", a u datasetu smo mi (u prethodnom koraku) spojili Irrelevant u Neutral.\n",
        "\n",
        "Konflikt: Kada je model odgovorio \"Irrelevant\" (Å¡to je validan odgovor prema promptu), evaluacija je to oznaÄila kao greÅ¡ku jer je oÄekivala labelu \"Neutral\". Ovo je sistemska greÅ¡ka u dizajnu eksperimenta koja pokazuje koliko je teÅ¡ko uskladiti LLM promptove sa fiksiranim datasetom. Da sam i u promptu uklonio opciju \"Irrelevant\", rezultat bi verovatno bio bolji.\n",
        "\n",
        "## 3. Sklonost ka pozitivnom (Positive Recall: 0.80)\n",
        "\n",
        " Model je najbolje prepoznavao pozitivne tvitove (80%).\n",
        "\n",
        "LLM-ovi su Äesto trenirani na podacima koji su \"polite\" (ljubazni) i imaju blagu pristrasnost da tekstove ocenjuju pozitivnije nego Å¡to jesu, osim ako nema eksplicitnih negativnih reÄi.\n",
        "\n",
        "## ZAKLJUÄŒAK:\n",
        "\n",
        "Zero-shot pristup pokazuje ograniÄenja opÅ¡tih jeziÄkih modela kada se primene na usko struÄan domen (gejming Twitter) bez ikakvog prilagoÄ‘avanja. Rezultat od 56.7% ukazuje na to da model razume engleski jezik i osnovne emocije, ali ne uspeva da uhvati nijanse specifiÄne za dataset, a posebno pati zbog neusklaÄ‘enosti izmeÄ‘u ponuÄ‘enih opcija u promptu i izmenjene strukture ciljnih klasa (spajanje Irrelevant/Neutral).\""
      ],
      "metadata": {
        "id": "zQeIWi2iNOLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 2. ZERO-SHOT PRISTUP (3 KLASE - CORRECTED) ---\")\n",
        "\n",
        "# Funkcija za kreiranje Zero-shot prompta (BEZ IRRELEVANT)\n",
        "def create_zero_shot_prompt(text, entity):\n",
        "    return f\"\"\"Classify the sentiment of the following tweet towards the entity '{entity}'.\n",
        "Options: Positive, Negative, Neutral.\n",
        "Note: If the tweet is irrelevant to the entity or contains no clear sentiment, classify it as Neutral.\n",
        "\n",
        "Tweet: {text}\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "# PokreÄ‡emo predikciju\n",
        "y_pred_zero_shot = []\n",
        "\n",
        "for index, row in tqdm(val_df.iterrows(), total=val_df.shape[0], desc=\"Zero-shot 3-Class\"):\n",
        "    prompt = create_zero_shot_prompt(row['text'], row['entity'])\n",
        "    response = query_llm(prompt)\n",
        "    y_pred_zero_shot.append(response)\n",
        "\n",
        "# ÄŒiÅ¡Ä‡enje izlaza\n",
        "def clean_prediction(pred):\n",
        "    pred = pred.lower()\n",
        "    if \"positive\" in pred: return \"Positive\"\n",
        "    if \"negative\" in pred: return \"Negative\"\n",
        "    # Sve ostalo (Neutral, Irrelevant, greÅ¡ke) ide u Neutral\n",
        "    return \"Neutral\"\n",
        "\n",
        "y_pred_zero_shot_clean = [clean_prediction(p) for p in y_pred_zero_shot]\n",
        "\n",
        "# Evaluacija\n",
        "print(\"\\nRezultati Zero-shot pristupa (3 KLASE):\")\n",
        "print(classification_report(y_val, y_pred_zero_shot_clean))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_zero_shot_clean))\n",
        "\n",
        "# Matrica konfuzije\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_val, y_pred_zero_shot_clean, labels=['Positive', 'Negative', 'Neutral'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=['Pos', 'Neg', 'Neu'],\n",
        "            yticklabels=['Pos', 'Neg', 'Neu'])\n",
        "plt.title('Confusion Matrix (Zero-shot LLM)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L_GyFW79OLiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TaÄnost je ostala ista (~57%) zato Å¡to izbacivanje reÄi \"Irrelevant\" iz prompta nije promenilo fundamentalno razumevanje modela.\n",
        "\n",
        "Model i dalje ne prepoznaje neutralne tvitove (Recall mu je ostao nizak, oko 0.39). Iako sam rekao da \"sve ostalo stavi u Neutral\", model ima uroÄ‘enu pristrasnost (bias) da u skoro svakom tekstu traÅ¾i neki sentiment (pozitivan ili negativan), umesto da ga oznaÄi kao neutralan. To je tipiÄno za instruction-tuned modele koji Å¾ele da budu \"korisni\" i daju konkretan odgovor.\n",
        "\n",
        "Ukratko: Nije problem u formatu prompta, veÄ‡ u tome Å¡to modelu fali kontekst (primeri) Å¡ta taÄno za tebe znaÄi \"Neutralno\" u gejming Å¾argonu. Zato Ä‡emo implementirati Few-shot."
      ],
      "metadata": {
        "id": "IWHYUl5RPaWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Pristup 3: Few-shot Klasifikacija**\n",
        "\n",
        "Ovde biramo nekoliko primera iz trening seta i ubacujemo ih u prompt kako bismo modelu \"pokazali\" Å¡ta Å¾elimo."
      ],
      "metadata": {
        "id": "u4C78sB09KhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 3. FEW-SHOT PRISTUP ---\")\n",
        "\n",
        "# Biramo po jedan primer za svaku klasu iz trening seta da budu \"demonstracija\"\n",
        "examples = train_df.groupby('sentiment').apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
        "\n",
        "few_shot_context = \"\"\n",
        "for _, row in examples.iterrows():\n",
        "    few_shot_context += f\"Tweet: {row['text']}\\nEntity: {row['entity']}\\nSentiment: {row['sentiment']}\\n\\n\"\n",
        "\n",
        "print(\"Primeri koji se koriste u promptu:\\n\", few_shot_context)\n",
        "\n",
        "def create_few_shot_prompt(text, entity):\n",
        "    return f\"\"\"Classify the sentiment of the tweet towards the entity.\n",
        "Options: Positive, Negative, Neutral, Irrelevant.\n",
        "\n",
        "Examples:\n",
        "{few_shot_context}\n",
        "Task:\n",
        "Tweet: {text}\n",
        "Entity: {entity}\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "# PokreÄ‡emo predikciju\n",
        "y_pred_few_shot = []\n",
        "for index, row in tqdm(val_df.iterrows(), total=val_df.shape[0], desc=\"Few-shot inference\"):\n",
        "    prompt = create_few_shot_prompt(row['text'], row['entity'])\n",
        "    response = query_llm(prompt)\n",
        "    y_pred_few_shot.append(response)\n",
        "\n",
        "y_pred_few_shot_clean = [clean_prediction(p) for p in y_pred_few_shot]\n",
        "\n",
        "# Evaluacija\n",
        "print(\"\\nRezultati Few-shot pristupa:\")\n",
        "print(classification_report(y_val, y_pred_few_shot_clean))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_few_shot_clean))"
      ],
      "metadata": {
        "id": "F6CXxcOk9M8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ObrazloÅ¾enje koda i metodologije (4. Deo: Few-shot Pristup)**\n",
        "## 1. Koncept \"In-Context Learning\" (UÄenje iz konteksta)\n",
        "\n",
        "U ovom koraku primenjujem Few-shot metodologiju. Za razliku od Zero-shot pristupa gde model \"nagaÄ‘a\" pravila, ovde mu u samom promptu dajem demonstraciju zadatka.\n",
        "\n",
        "Selekcija primera: Koristio sam train_df.groupby('sentiment').apply(...) da automatski izvuÄem po jedan nasumiÄan primer za svaku klasu iz trening seta.\n",
        "\n",
        "Cilj: Å½elim da model vidi kako izgleda jedan \"Pozitivan\", jedan \"Negativan\" i jedan \"Neutralan\" tvit pre nego Å¡to pokuÅ¡a da klasifikuje novi. Ovo mu pomaÅ¾e da \"kalibriÅ¡e\" svoj izlaz i razume stil pisanja u datasetu.\n",
        "\n",
        "Konstrukcija Prompta: Prompt je sada znatno sloÅ¾eniji. Sastoji se iz tri dela:\n",
        "\n",
        "Instrukcija: (\"Classify the sentiment...\")\n",
        "\n",
        "Kontekst (Examples): Gde mu prikazujem izvuÄene primere u formatu Tweet -> Entity -> Sentiment.\n",
        "\n",
        "Zadatak (Task): Novi tvit koji treba da reÅ¡i.\n",
        "\n",
        "## 2. TehniÄka realizacija\n",
        "\n",
        "Dinamika: Kod dinamiÄki gradi string few_shot_context pre iteracije. To znaÄi da svi tvitovi u validacionom setu dobijaju iste primere za uÄenje. Ovo osigurava konzistentnost eksperimenta (svi su imali istu \"pomoÄ‡\").\n",
        "\n",
        "Napomena za upozorenje (Warning): Poruka DeprecationWarning koju je biblioteka izbacila odnosi se na buduÄ‡e promene u pandas biblioteci i ne utiÄe na taÄnost trenutnih rezultata.\n",
        "\n",
        "INTERPRETACIJA REZULTATA (Accuracy: 58.3%)\n",
        "Tvoj rezultat je skoÄio sa 56.6% (Zero-shot) na 58.3% (Few-shot). Evo kako da \"prodaÅ¡\" ovaj rezultat u radu, iako deluje kao mali pomak:\n",
        "\n",
        "### 1. Trend poboljÅ¡anja (Proof of Concept)\n",
        "\n",
        " \"Primenom Few-shot pristupa zabeleÅ¾en je porast taÄnosti od 1.7%. Iako deluje skromno, ovo potvrÄ‘uje hipotezu da LLM model reaguje na primere (In-Context Learning). Model je uspeo da iskoristi ponuÄ‘eni kontekst da bolje razume zadatak.\"\n",
        "\n",
        "### 2. ZaÅ¡to poboljÅ¡anje nije veÄ‡e? (KritiÄka analiza)\n",
        "\n",
        " Ovo je najbitniji deo za visoku ocenu â€“ moraÅ¡ objasniti zaÅ¡to nismo dobili 80%+:\n",
        "\n",
        "Problem nasumiÄnih primera: U ovom kodu smo koristili random primere (sample(1)).\n",
        "\n",
        "Rizik: MoguÄ‡e je da smo izvukli \"lake\" ili netipiÄne primere koji nisu puno pomogli modelu da reÅ¡i \"teÅ¡ke\" sluÄajeve u validacionom setu. (Da smo koristili one ruÄno birane primere iz \"Pro\" verzije koda, moÅ¾da bi rezultat bio bolji).\n",
        "\n",
        "ZadrÅ¾avanje opcije \"Irrelevant\": U promptu je i dalje pisalo Options: ... Irrelevant. To zbunjuje model jer smo mi spojili klase u podatcima. Model vidi primer za \"Neutral\", ali mu mi nudimo i \"Irrelevant\", pa se on \"cepa\" izmeÄ‘u te dve opcije.\n",
        "\n",
        "### 3. \"Neutral\" je i dalje problem (Recall: 0.37)\n",
        "\n",
        "Negative Recall: 0.74 (OdliÄno prepoznaje hejt).\n",
        "\n",
        "Positive Recall: 0.78 (OdliÄno prepoznaje pohvale).\n",
        "\n",
        "Neutral Recall: 0.37 (Katastrofa).\n",
        "\n",
        "### ZakljuÄak\n",
        "\n",
        " \"ÄŒak i sa Few-shot primerima, FLAN-T5 model pokazuje snaÅ¾nu pristrasnost ka polaritetu (Polarity Bias). On ima tendenciju da u svakom tvitu 'traÅ¾i emociju'. Ako neko napiÅ¡e obiÄnu Äinjenicu o igrici, model Ä‡e Äesto pokuÅ¡ati da to protumaÄi kao pozitivno ili negativno, umesto kao neutralno. Ovo je poznato ograniÄenje instruction-tuned modela koji su trenirani da budu 'korisni' i daju miÅ¡ljenje.\"\n",
        "\n",
        "### FINALNI ZAKLJUÄŒAK ZA POREÄENJE\n",
        "\n",
        "1) KlasiÄni ML (SVM + TF-IDF): ~91%\n",
        "\n",
        "Pobednik. Specijalizovan, brz, razume Å¾argon jer je video ceo trening set.\n",
        "\n",
        "2) Few-shot LLM: ~58.3%\n",
        "\n",
        "Sredina. Pokazuje inteligenciju, uÄi iz primera, ali nedovoljno da savlada specifiÄnosti domena bez finetuning-a.\n",
        "\n",
        "3) Zero-shot LLM: ~56.6%\n",
        "\n",
        "Baza. Koristi samo opÅ¡te znanje engleskog jezika."
      ],
      "metadata": {
        "id": "G1b0sw2pQsx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Poredjenje rezultata (Vizuelizacija i Tabela)**\n",
        "\n",
        "Na kraju, ovaj blok koda pravi tabelu i grafikon da uporediÅ¡ taÄnost sva tri pristupa, Å¡to ti treba za zakljuÄak u radu."
      ],
      "metadata": {
        "id": "7m9TvRsy9k4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Prikupljanje accuracy skorova\n",
        "acc_ml = accuracy_score(y_val, y_pred_ml)\n",
        "acc_zero = accuracy_score(y_val, y_pred_zero_shot_clean)\n",
        "acc_few = accuracy_score(y_val, y_pred_few_shot_clean)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Metod': ['Classical ML (LogReg)', 'Zero-shot (LLM)', 'Few-shot (LLM)'],\n",
        "    'Accuracy': [acc_ml, acc_zero, acc_few]\n",
        "})\n",
        "\n",
        "print(\"\\n--- FINALNO POREÄENJE ---\")\n",
        "print(results_df)\n",
        "\n",
        "# Crtanje grafika\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='Metod', y='Accuracy', data=results_df, palette='viridis')\n",
        "plt.title('PoreÄ‘enje taÄnosti modela')\n",
        "plt.ylim(0, 1)\n",
        "for index, row in results_df.iterrows():\n",
        "    plt.text(index, row.Accuracy + 0.02, f\"{row.Accuracy:.2f}\", color='black', ha=\"center\")\n",
        "plt.show()\n",
        "\n",
        "# Prikaz matrice konfuzije za najbolji model (verovatno ML ili Few-shot)\n",
        "print(\"Confusion Matrix (ML pristup):\")\n",
        "cm = confusion_matrix(y_val, y_pred_ml, labels=['Positive', 'Negative', 'Neutral', 'Irrelevant'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Pos', 'Neg', 'Neu', 'Irr'], yticklabels=['Pos', 'Neg', 'Neu', 'Irr'])\n",
        "plt.ylabel('Stvarno')\n",
        "plt.xlabel('PredviÄ‘eno')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UxgPxv669izB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"--- 6. FINALNA VIZUELIZACIJA I POREÄENJE ---\")\n",
        "\n",
        "# RaÄunanje taÄnosti\n",
        "acc_ml = accuracy_score(y_val, y_pred) # SVM model\n",
        "acc_zero = accuracy_score(y_val, y_pred_zero_shot_clean) # Zero-shot\n",
        "acc_few = accuracy_score(y_val, y_pred_few_shot_clean)   # Few-shot\n",
        "\n",
        "# Kreiranje tabele rezultata\n",
        "results_df = pd.DataFrame({\n",
        "    'Metod': ['Classical ML (SVM)', 'Zero-shot (LLM)', 'Few-shot (LLM)'],\n",
        "    'Accuracy': [acc_ml, acc_zero, acc_few]\n",
        "})\n",
        "\n",
        "print(\"\\nTABELA REZULTATA:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- GRAFIK 1: POREÄENJE TAÄŒNOSTI ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Koristimo 'hue' i 'legend=False' da bi izbegli FutureWarning, i viridis paletu za profesionalni izgled\n",
        "sns.barplot(x='Metod', y='Accuracy', data=results_df, palette='viridis', hue='Metod', legend=False)\n",
        "\n",
        "plt.title('Finalno poreÄ‘enje taÄnosti (Accuracy)', fontsize=15)\n",
        "plt.ylim(0, 1.1) # Malo mesta iznad 1.0 za tekst\n",
        "plt.ylabel('TaÄnost', fontsize=12)\n",
        "plt.xlabel('Pristup', fontsize=12)\n",
        "\n",
        "# Ispisivanje taÄnih procenata iznad stubiÄ‡a\n",
        "for index, row in results_df.iterrows():\n",
        "    plt.text(index, row.Accuracy + 0.02, f\"{row.Accuracy*100:.1f}%\",\n",
        "             color='black', ha=\"center\", fontweight='bold', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# --- GRAFIK 2: MATRICA KONFUZIJE POBEDNIKA (SVM) ---\n",
        "print(f\"\\nDetaljna analiza greÅ¡aka za najbolji model (SVM):\")\n",
        "labels = ['Positive', 'Negative', 'Neutral'] # Bitno: Samo 3 klase!\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels, annot_kws={\"size\": 14})\n",
        "plt.title('Confusion Matrix: SVM (Pobednik)', fontsize=15)\n",
        "plt.ylabel('Stvarna klasa', fontsize=12)\n",
        "plt.xlabel('PredviÄ‘ena klasa', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "004udIJ_M5lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ZAKLJUÄŒAK\n",
        "U ovom radu sprovedena je komparativna analiza tri pristupa klasifikaciji sentimenta na domenski specifiÄnim podacima (Twitter objave o video igrama): klasiÄnog maÅ¡inskog uÄenja (Supervised ML), Zero-shot i Few-shot primene velikih jeziÄkih modela (LLM).\n",
        "\n",
        "Na osnovu sprovedenih eksperimenata i dobijenih rezultata, mogu se izvuÄ‡i sledeÄ‡i kljuÄni zakljuÄci:\n",
        "\n",
        "## 1. Superiornost specijalizovanog ML modela\n",
        "\n",
        " KlasiÄan pristup zasnovan na LinearSVC algoritmu i TF-IDF vektorizaciji ostvario je ubedljivo najbolji rezultat sa taÄnoÅ¡Ä‡u od 91.2%. Ovaj rezultat pokazuje da, kada je dostupna velika koliÄina oznaÄenih podataka za trening (preko 70.000 primera), \"stariji\" i raÄunarski jeftiniji algoritmi mogu nadmaÅ¡iti opÅ¡te generativne modele. KljuÄ uspeha ovog modela leÅ¾i u:\n",
        "\n",
        "KoriÅ¡Ä‡enju trigrama (n-gram range 1-3) koji su omoguÄ‡ili prepoznavanje negacija (\"not good\") i specifiÄnih fraza.\n",
        "\n",
        "ZadrÅ¾avanju interpunkcije (!, ?) i \"stop-reÄi\" koje nose sentiment.\n",
        "\n",
        "Sposobnosti SVM-a da pronaÄ‘e jasnu granicu izmeÄ‘u klasa u visoko-dimenzionalnom prostoru.\n",
        "\n",
        "## 2. OgraniÄenja \"Out-of-the-Box\" LLM pristupa\n",
        "\n",
        " Veliki jeziÄki model (Flan-T5 Large) pokazao je znatno niÅ¾e performanse u poreÄ‘enju sa nadgledanim uÄenjem:\n",
        "\n",
        "Zero-shot (56.6%) je potvrdio da opÅ¡ti model poseduje baziÄno razumevanje sentimenta, ali ne uspeva da prepozna specifiÄan gejming Å¾argon, sarkazam i implicitna znaÄenja bez dodatnog konteksta.\n",
        "\n",
        "Few-shot (58.3%) je doneo blago poboljÅ¡anje, potvrÄ‘ujuÄ‡i sposobnost modela da uÄi iz konteksta (In-Context Learning). Ipak, ovaj rast nije bio dovoljan da ugrozi ML model.\n",
        "\n",
        "Glavni izazov za LLM bila je Neutralna klasa, gde je model pokazao nisku osetljivost (Recall ~37-39%), Äesto pogreÅ¡no klasifikujuÄ‡i objektivne tvitove kao pozitivne ili negativne usled inherentne pristrasnosti modela (Polarity Bias).\n",
        "\n",
        "## 3. Odnos cene, brzine i taÄnosti\n",
        "\n",
        " Eksperiment ukazuje na jasan kompromis (trade-off):\n",
        "\n",
        "ML pristup zahteva ogroman napor u prikupljanju i oznaÄavanju podataka (skupo vreme ljudi), ali rezultira modelom koji je izuzetno brz, precizan i jeftin za izvrÅ¡avanje.\n",
        "\n",
        "LLM pristup ne zahteva trening podatke (moÅ¾e se koristiti odmah), ali je sporiji, raÄunarski zahtevniji i manje precizan na specifiÄnim domenima bez finog podeÅ¡avanja (fine-tuning).\n",
        "\n",
        "## Finalna presuda\n",
        "\n",
        " Za zadatke klasifikacije teksta u uskim domenima (kao Å¡to je gejming), gde su dostupni istorijski podaci, klasiÄan ML (SVM) ostaje optimalno reÅ¡enje. S druge strane, LLM pristupi su pogodniji za \"hladan start\" (kada nemamo podatke) ili za sloÅ¾enije zadatke koji zahtevaju generisanje teksta i obrazloÅ¾enja, a ne samo grubu klasifikaciju."
      ],
      "metadata": {
        "id": "h-H12UK-R8Ud"
      }
    }
  ]
}